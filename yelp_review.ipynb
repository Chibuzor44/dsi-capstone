{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "        .master(\"local[64]\") \\\n",
    "        .appName(\"df lecture\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "from pyspark.sql import SQLContext\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression as spark_LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "import cleaner\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = \"s3://chizzy/yelp_data/\"\n",
    "df_bus = pd.read_json(f_path+\"business.json\", lines=True)\n",
    "df_user = pd.read_json(f_path+\"user.json\", lines=True)\n",
    "df_rev = pd.read_json(f_path+\"review.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855 E Warner Rd, Ste B9</td>\n",
       "      <td>{'AcceptsInsurance': True, 'ByAppointmentOnly'...</td>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>[Dentists, General Dentistry, Health &amp; Medical...</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>{'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>Dental by Design</td>\n",
       "      <td></td>\n",
       "      <td>85044</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101 Washington Rd</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>[Hair Stylists, Hair Salons, Men's Hair Salons...</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>{'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>Stephen Szabo Salon</td>\n",
       "      <td></td>\n",
       "      <td>15317</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6025 N 27th Ave, Ste 1</td>\n",
       "      <td>{}</td>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>[Departments of Motor Vehicles, Public Service...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>Western Motor Vehicle</td>\n",
       "      <td></td>\n",
       "      <td>85017</td>\n",
       "      <td>18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000 Arizona Mills Cr, Ste 435</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>[Sporting Goods, Shopping]</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "      <td>0</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>Sports Authority</td>\n",
       "      <td></td>\n",
       "      <td>85282</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581 Howe Ave</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...</td>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>[American (New), Nightlife, Bars, Sandwiches, ...</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>{'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>Brick House Tavern + Tap</td>\n",
       "      <td></td>\n",
       "      <td>44221</td>\n",
       "      <td>116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0        4855 E Warner Rd, Ste B9   \n",
       "1              3101 Washington Rd   \n",
       "2          6025 N 27th Ave, Ste 1   \n",
       "3  5000 Arizona Mills Cr, Ste 435   \n",
       "4                    581 Howe Ave   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'AcceptsInsurance': True, 'ByAppointmentOnly'...  FYWN1wneV18bWNgQjJ2GNg   \n",
       "1  {'BusinessParking': {'garage': False, 'street'...  He-G7vWjzVUysIKrfNbPUQ   \n",
       "2                                                 {}  KQPW8lFf1y5BT2MxiSZ3QA   \n",
       "3  {'BusinessAcceptsCreditCards': True, 'Restaura...  8DShNS-LuFqpEWIp0HxijA   \n",
       "4  {'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...  PfOCPjBrlQAnz__NXj9h_w   \n",
       "\n",
       "                                          categories            city  \\\n",
       "0  [Dentists, General Dentistry, Health & Medical...       Ahwatukee   \n",
       "1  [Hair Stylists, Hair Salons, Men's Hair Salons...        McMurray   \n",
       "2  [Departments of Motor Vehicles, Public Service...         Phoenix   \n",
       "3                         [Sporting Goods, Shopping]           Tempe   \n",
       "4  [American (New), Nightlife, Bars, Sandwiches, ...  Cuyahoga Falls   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...        1  33.330690   \n",
       "1  {'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...        1  40.291685   \n",
       "2                                                 {}        1  33.524903   \n",
       "3  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        0  33.383147   \n",
       "4  {'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...        1  41.119535   \n",
       "\n",
       "    longitude                      name neighborhood postal_code  \\\n",
       "0 -111.978599          Dental by Design                    85044   \n",
       "1  -80.104900       Stephen Szabo Salon                    15317   \n",
       "2 -112.115310     Western Motor Vehicle                    85017   \n",
       "3 -111.964725          Sports Authority                    85282   \n",
       "4  -81.475690  Brick House Tavern + Tap                    44221   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            22    4.0    AZ  \n",
       "1            11    3.0    PA  \n",
       "2            18    1.5    AZ  \n",
       "3             9    3.0    AZ  \n",
       "4           116    3.5    OH  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>oMy_rEb0UBEmMlu-zcxnoQ</td>\n",
       "      <td>2014-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ-aSuM4pCFPdkfoZ34q0Q</td>\n",
       "      <td>2013-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiffy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uUzsFQn_6cXDh6rPNGbIFA</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>mBneaEEH5EMyxaVyqS-72A</td>\n",
       "      <td>2015-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W5mJGs-dcDWRGEhAzUYtoA</td>\n",
       "      <td>2016-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.67                0                0                 0   \n",
       "1           3.70                0                0                 0   \n",
       "2           2.00                0                0                 0   \n",
       "3           4.67                0                0                 0   \n",
       "4           4.67                0                0                 0   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain      ...        cool  elite  fans  \\\n",
       "0                  0                 1      ...           0     []     0   \n",
       "1                  0                 0      ...           0     []     0   \n",
       "2                  0                 0      ...           0     []     0   \n",
       "3                  0                 0      ...           0     []     0   \n",
       "4                  0                 0      ...           0     []     0   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  [cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...      0  Johnny   \n",
       "1  [0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...      0   Chris   \n",
       "2                                                 []      0   Tiffy   \n",
       "3                                                 []      0    Mark   \n",
       "4                                                 []      0  Evelyn   \n",
       "\n",
       "   review_count useful                 user_id  yelping_since  \n",
       "0             8      0  oMy_rEb0UBEmMlu-zcxnoQ     2014-11-03  \n",
       "1            10      0  JJ-aSuM4pCFPdkfoZ34q0Q     2013-09-24  \n",
       "2             1      0  uUzsFQn_6cXDh6rPNGbIFA     2017-03-02  \n",
       "3             6      0  mBneaEEH5EMyxaVyqS-72A     2015-03-13  \n",
       "4             3      0  W5mJGs-dcDWRGEhAzUYtoA     2016-09-08  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0W4lkclzZThpx3V65bVgig</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>v0i_UHJMo_hPBq9bxWvW4w</td>\n",
       "      <td>5</td>\n",
       "      <td>Love the staff, love the meat, love the place....</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>5</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>5</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>4</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny               review_id  \\\n",
       "0  0W4lkclzZThpx3V65bVgig     0 2016-05-28      0  v0i_UHJMo_hPBq9bxWvW4w   \n",
       "1  AEx2SYEUJmTxVVB18LlCwA     0 2016-05-28      0  vkVSCC7xljjrAI4UGfnKEQ   \n",
       "2  VR6GpWIda3SfvPC-lg9H3w     0 2016-05-28      0  n6QzIUObkYshz4dz2QRJTw   \n",
       "3  CKC0-MOWMqoeWf6s-szl8g     0 2016-05-28      0  MV3CcKScW05u5LVfF6ok0g   \n",
       "4  ACFtxLv8pGrrxMm6EgjreA     0 2016-05-28      0  IXvOzsEMYtiJI0CARmj77Q   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      5  Love the staff, love the meat, love the place....       0   \n",
       "1      5  Super simple place but amazing nonetheless. It...       0   \n",
       "2      5  Small unassuming place that changes their menu...       0   \n",
       "3      5  Lester's is located in a beautiful neighborhoo...       0   \n",
       "4      4  Love coming here. Yes the place always needs t...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  bv2nCi5Qv5vroFiqKGopiw  \n",
       "1  bv2nCi5Qv5vroFiqKGopiw  \n",
       "2  bv2nCi5Qv5vroFiqKGopiw  \n",
       "3  bv2nCi5Qv5vroFiqKGopiw  \n",
       "4  bv2nCi5Qv5vroFiqKGopiw  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename colume names \n",
    "df_bus.rename(columns={\"name\":\"bus_name\",\"review_count\":\"bus_rev_count\"}, inplace=True)\n",
    "df_user.rename(columns={\"name\":\"user_name\", \"review_count\":\"user_rev_count\"}, inplace=True)\n",
    "df_rev.rename(columns={\"cool\":\"cool_rev\", \"funny\":\"funny_rev\", \"stars\":\"stars_rev\", \"useful\":\"useful_rev\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for business table: 128302\n",
      "Number of rows for user table: 1326101\n",
      "Number of rows for review table: 5261669\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows for business table: {}\".format(len(df_bus)))\n",
    "print(\"Number of rows for user table: {}\".format(len(df_user)))\n",
    "print(\"Number of rows for review table: {}\".format(len(df_rev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\", \\\n",
    "            \"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\", \\\n",
    "            \"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"]\n",
    "\n",
    "#Extracting reviews for only US restaurants\n",
    "df_bus_us = df_bus[df_bus.state.isin (us_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for business table for US states: 128302\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows for business table for US states: {}\".format(len(df_bus_us)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_bus = pd.merge(df_rev, df_bus, how='inner', on=['business_id', 'business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool_rev</th>\n",
       "      <th>date</th>\n",
       "      <th>funny_rev</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_rev</th>\n",
       "      <th>text</th>\n",
       "      <th>useful_rev</th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bus_name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>bus_rev_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>0</td>\n",
       "      <td>HRPm3vEZ_F-33TYVT7Pebw</td>\n",
       "      <td>5</td>\n",
       "      <td>Cycle Pub Las Vegas was a blast! Got a groupon...</td>\n",
       "      <td>1</td>\n",
       "      <td>_4iMDXbXZ1p1ONG297YEAQ</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>36.171869</td>\n",
       "      <td>-115.142146</td>\n",
       "      <td>Vegas Pub Crawler</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>89101</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-03-12</td>\n",
       "      <td>2</td>\n",
       "      <td>31uIbU4c10W5X5Fv506ryA</td>\n",
       "      <td>4</td>\n",
       "      <td>Cycle pub it is......\\nTalk about having a gre...</td>\n",
       "      <td>6</td>\n",
       "      <td>JlwWHBFT76iSJe5mWIcZ4A</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>36.171869</td>\n",
       "      <td>-115.142146</td>\n",
       "      <td>Vegas Pub Crawler</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>89101</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>3WBCOXjwKnuu01pNljDKGg</td>\n",
       "      <td>5</td>\n",
       "      <td>I've wanted to do Cycle Pub since spying it at...</td>\n",
       "      <td>6</td>\n",
       "      <td>Q6CEHR-6P-gQbNtzCAj4Ig</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>36.171869</td>\n",
       "      <td>-115.142146</td>\n",
       "      <td>Vegas Pub Crawler</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>89101</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>0</td>\n",
       "      <td>3AbYdLNW2NbGsD_YM1a78w</td>\n",
       "      <td>5</td>\n",
       "      <td>Had such a great time. Now I want to do Vegas ...</td>\n",
       "      <td>0</td>\n",
       "      <td>WF0_ES4qpeBqBxqqTLyT4g</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>36.171869</td>\n",
       "      <td>-115.142146</td>\n",
       "      <td>Vegas Pub Crawler</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>89101</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>XIzPfkbRNMumLLk5qYndDQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Ben is awesome! Fun, fantastic, wonderful expe...</td>\n",
       "      <td>0</td>\n",
       "      <td>VPA1wfF_-_bwNmyTgELRnw</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>36.171869</td>\n",
       "      <td>-115.142146</td>\n",
       "      <td>Vegas Pub Crawler</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>89101</td>\n",
       "      <td>38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool_rev       date  funny_rev  \\\n",
       "0  8QWPlVQ6D-OExqXoaD2Z1g         0 2014-09-24          0   \n",
       "1  8QWPlVQ6D-OExqXoaD2Z1g         3 2014-03-12          2   \n",
       "2  8QWPlVQ6D-OExqXoaD2Z1g         0 2014-04-15          0   \n",
       "3  8QWPlVQ6D-OExqXoaD2Z1g         0 2017-08-04          0   \n",
       "4  8QWPlVQ6D-OExqXoaD2Z1g         0 2016-03-30          0   \n",
       "\n",
       "                review_id  stars_rev  \\\n",
       "0  HRPm3vEZ_F-33TYVT7Pebw          5   \n",
       "1  31uIbU4c10W5X5Fv506ryA          4   \n",
       "2  3WBCOXjwKnuu01pNljDKGg          5   \n",
       "3  3AbYdLNW2NbGsD_YM1a78w          5   \n",
       "4  XIzPfkbRNMumLLk5qYndDQ          5   \n",
       "\n",
       "                                                text  useful_rev  \\\n",
       "0  Cycle Pub Las Vegas was a blast! Got a groupon...           1   \n",
       "1  Cycle pub it is......\\nTalk about having a gre...           6   \n",
       "2  I've wanted to do Cycle Pub since spying it at...           6   \n",
       "3  Had such a great time. Now I want to do Vegas ...           0   \n",
       "4  Ben is awesome! Fun, fantastic, wonderful expe...           0   \n",
       "\n",
       "                  user_id       address  ...  hours is_open   latitude  \\\n",
       "0  _4iMDXbXZ1p1ONG297YEAQ  201 N 3rd St  ...     {}       1  36.171869   \n",
       "1  JlwWHBFT76iSJe5mWIcZ4A  201 N 3rd St  ...     {}       1  36.171869   \n",
       "2  Q6CEHR-6P-gQbNtzCAj4Ig  201 N 3rd St  ...     {}       1  36.171869   \n",
       "3  WF0_ES4qpeBqBxqqTLyT4g  201 N 3rd St  ...     {}       1  36.171869   \n",
       "4  VPA1wfF_-_bwNmyTgELRnw  201 N 3rd St  ...     {}       1  36.171869   \n",
       "\n",
       "    longitude           bus_name  neighborhood  postal_code bus_rev_count  \\\n",
       "0 -115.142146  Vegas Pub Crawler      Downtown        89101            38   \n",
       "1 -115.142146  Vegas Pub Crawler      Downtown        89101            38   \n",
       "2 -115.142146  Vegas Pub Crawler      Downtown        89101            38   \n",
       "3 -115.142146  Vegas Pub Crawler      Downtown        89101            38   \n",
       "4 -115.142146  Vegas Pub Crawler      Downtown        89101            38   \n",
       "\n",
       "  stars state  \n",
       "0   4.5    NV  \n",
       "1   4.5    NV  \n",
       "2   4.5    NV  \n",
       "3   4.5    NV  \n",
       "4   4.5    NV  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev_bus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev_bus_user = pd.merge(df_rev_bus, df_user, how='left', on=['user_id', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for business table for concated business, user and review: 4391457\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows for business table for concated business, user and review: {}\".format(len(df_rev_bus_user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool_rev</th>\n",
       "      <th>date</th>\n",
       "      <th>funny_rev</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_rev</th>\n",
       "      <th>text</th>\n",
       "      <th>useful_rev</th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_rev_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>0</td>\n",
       "      <td>HRPm3vEZ_F-33TYVT7Pebw</td>\n",
       "      <td>5</td>\n",
       "      <td>Cycle Pub Las Vegas was a blast! Got a groupon...</td>\n",
       "      <td>1</td>\n",
       "      <td>_4iMDXbXZ1p1ONG297YEAQ</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Robert</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-03-12</td>\n",
       "      <td>2</td>\n",
       "      <td>31uIbU4c10W5X5Fv506ryA</td>\n",
       "      <td>4</td>\n",
       "      <td>Cycle pub it is......\\nTalk about having a gre...</td>\n",
       "      <td>6</td>\n",
       "      <td>JlwWHBFT76iSJe5mWIcZ4A</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1636</td>\n",
       "      <td>[2015, 2014, 2016]</td>\n",
       "      <td>23</td>\n",
       "      <td>[E19IMURE4WEoCnvDx-bylg, kJ9Wd9nq5BV0bSA9V98mV...</td>\n",
       "      <td>1091</td>\n",
       "      <td>Trev</td>\n",
       "      <td>212</td>\n",
       "      <td>1392</td>\n",
       "      <td>2014-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>3WBCOXjwKnuu01pNljDKGg</td>\n",
       "      <td>5</td>\n",
       "      <td>I've wanted to do Cycle Pub since spying it at...</td>\n",
       "      <td>6</td>\n",
       "      <td>Q6CEHR-6P-gQbNtzCAj4Ig</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[kiao9cLyffXHVth0B1FwfA, lcf0ZgVioqgFzU5QW73am...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>0</td>\n",
       "      <td>3AbYdLNW2NbGsD_YM1a78w</td>\n",
       "      <td>5</td>\n",
       "      <td>Had such a great time. Now I want to do Vegas ...</td>\n",
       "      <td>0</td>\n",
       "      <td>WF0_ES4qpeBqBxqqTLyT4g</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>Lexy</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>XIzPfkbRNMumLLk5qYndDQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Ben is awesome! Fun, fantastic, wonderful expe...</td>\n",
       "      <td>0</td>\n",
       "      <td>VPA1wfF_-_bwNmyTgELRnw</td>\n",
       "      <td>201 N 3rd St</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Cee</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool_rev       date  funny_rev  \\\n",
       "0  8QWPlVQ6D-OExqXoaD2Z1g         0 2014-09-24          0   \n",
       "1  8QWPlVQ6D-OExqXoaD2Z1g         3 2014-03-12          2   \n",
       "2  8QWPlVQ6D-OExqXoaD2Z1g         0 2014-04-15          0   \n",
       "3  8QWPlVQ6D-OExqXoaD2Z1g         0 2017-08-04          0   \n",
       "4  8QWPlVQ6D-OExqXoaD2Z1g         0 2016-03-30          0   \n",
       "\n",
       "                review_id  stars_rev  \\\n",
       "0  HRPm3vEZ_F-33TYVT7Pebw          5   \n",
       "1  31uIbU4c10W5X5Fv506ryA          4   \n",
       "2  3WBCOXjwKnuu01pNljDKGg          5   \n",
       "3  3AbYdLNW2NbGsD_YM1a78w          5   \n",
       "4  XIzPfkbRNMumLLk5qYndDQ          5   \n",
       "\n",
       "                                                text  useful_rev  \\\n",
       "0  Cycle Pub Las Vegas was a blast! Got a groupon...           1   \n",
       "1  Cycle pub it is......\\nTalk about having a gre...           6   \n",
       "2  I've wanted to do Cycle Pub since spying it at...           6   \n",
       "3  Had such a great time. Now I want to do Vegas ...           0   \n",
       "4  Ben is awesome! Fun, fantastic, wonderful expe...           0   \n",
       "\n",
       "                  user_id       address      ...      compliment_writer  cool  \\\n",
       "0  _4iMDXbXZ1p1ONG297YEAQ  201 N 3rd St      ...                      0     0   \n",
       "1  JlwWHBFT76iSJe5mWIcZ4A  201 N 3rd St      ...                     57  1636   \n",
       "2  Q6CEHR-6P-gQbNtzCAj4Ig  201 N 3rd St      ...                      0     7   \n",
       "3  WF0_ES4qpeBqBxqqTLyT4g  201 N 3rd St      ...                      0     0   \n",
       "4  VPA1wfF_-_bwNmyTgELRnw  201 N 3rd St      ...                      0     0   \n",
       "\n",
       "                elite fans                                            friends  \\\n",
       "0                  []    0                                                 []   \n",
       "1  [2015, 2014, 2016]   23  [E19IMURE4WEoCnvDx-bylg, kJ9Wd9nq5BV0bSA9V98mV...   \n",
       "2                  []    0  [kiao9cLyffXHVth0B1FwfA, lcf0ZgVioqgFzU5QW73am...   \n",
       "3                  []    1                                                 []   \n",
       "4                  []    0                                                 []   \n",
       "\n",
       "   funny  user_name user_rev_count useful yelping_since  \n",
       "0      0     Robert              1      0    2012-05-13  \n",
       "1   1091       Trev            212   1392    2014-02-06  \n",
       "2      0      Jaime              2      0    2013-04-27  \n",
       "3      2       Lexy             17      2    2010-07-10  \n",
       "4      0        Cee              2      0    2014-12-06  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev_bus_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4391457 entries, 0 to 4391456\n",
      "Data columns (total 44 columns):\n",
      "business_id           object\n",
      "cool_rev              int64\n",
      "date                  datetime64[ns]\n",
      "funny_rev             int64\n",
      "review_id             object\n",
      "stars_rev             int64\n",
      "text                  object\n",
      "useful_rev            int64\n",
      "user_id               object\n",
      "address               object\n",
      "attributes            object\n",
      "categories            object\n",
      "city                  object\n",
      "hours                 object\n",
      "is_open               int64\n",
      "latitude              float64\n",
      "longitude             float64\n",
      "bus_name              object\n",
      "neighborhood          object\n",
      "postal_code           object\n",
      "bus_rev_count         int64\n",
      "stars                 float64\n",
      "state                 object\n",
      "average_stars         float64\n",
      "compliment_cool       int64\n",
      "compliment_cute       int64\n",
      "compliment_funny      int64\n",
      "compliment_hot        int64\n",
      "compliment_list       int64\n",
      "compliment_more       int64\n",
      "compliment_note       int64\n",
      "compliment_photos     int64\n",
      "compliment_plain      int64\n",
      "compliment_profile    int64\n",
      "compliment_writer     int64\n",
      "cool                  int64\n",
      "elite                 object\n",
      "fans                  int64\n",
      "friends               object\n",
      "funny                 int64\n",
      "user_name             object\n",
      "user_rev_count        int64\n",
      "useful                int64\n",
      "yelping_since         object\n",
      "dtypes: datetime64[ns](1), float64(4), int64(22), object(17)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "df_rev_bus_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_df = spark.read.json('../break_week/data/dataset/review.json')\n",
    "# user_df = spark.read.json('../break_week/data/dataset/user.json')\n",
    "# business_df = spark.read.json(\"../break_week/data/dataset/business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review_df.createTempView(\"review\")\n",
    "# user_df.createTempView(\"user\")\n",
    "# business_df.createTempView(\"business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = spark.sql(\"\"\"SELECT new.user_name, new.user_id, new.business_id, new.friends, \\\n",
    "#                 b.name AS business_name, b.state, b.city, b.address, b.categories, b.stars AS bus_star,\\\n",
    "#                 new.text, new.stars AS review_star \\\n",
    "#                 FROM \\\n",
    "#                     (SELECT u.name AS user_name, r.user_id, r.business_id, r.text, r.stars, u.friends \\\n",
    "#                     FROM review AS r \\\n",
    "#                     LEFT JOIN user AS u \\\n",
    "#                     ON r.user_id = u.user_id) AS new\\\n",
    "#                 INNER JOIN business as b\\\n",
    "#                 ON new.business_id = b.business_id \\\n",
    "#                 WHERE ARRAY_CONTAINS(b.categories, 'Restaurants') \\\n",
    "#                 AND b.state IN (\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\", \\\n",
    "#                                 \"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\", \\\n",
    "#                                 \"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\") \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1_5 = df.filter(\"review_star = 1 OR review_star = 5\")\n",
    "# df_1_5.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1_5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1_5.select(\"state\").groupBy(\"state\").count().show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df_1_5.where(\"state = 'WI'\").select([\"text\", \"review_star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "# wordsData = tokenizer.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wi = df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars_rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cycle Pub Las Vegas was a blast! Got a groupon...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cycle pub it is......\\nTalk about having a gre...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've wanted to do Cycle Pub since spying it at...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had such a great time. Now I want to do Vegas ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ben is awesome! Fun, fantastic, wonderful expe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars_rev\n",
       "0  Cycle Pub Las Vegas was a blast! Got a groupon...          5\n",
       "1  Cycle pub it is......\\nTalk about having a gre...          4\n",
       "2  I've wanted to do Cycle Pub since spying it at...          5\n",
       "3  Had such a great time. Now I want to do Vegas ...          5\n",
       "4  Ben is awesome! Fun, fantastic, wonderful expe...          5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_rev_bus_user[[\"text\", \"stars_rev\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(80000)\n",
    "corpus = df1[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Had such a great time. Now I want to do Vegas Pub Crawler every time I come to Vegas. There were three separate groups on our ride. Two larger groups and then me & my husband. We used a Groupon. All you need to do is show it to the driver on your phone/printed out and he'll take a photo of it. Super easy. We were all a bit timid at first, but our driver Jon loosened us up and kept us happy! We spent about 20 minutes at 5 spots. They were all decently close - a few blocks apart. There is no drinking on the actual vehicle. But that wasn't an issue since we were stopping and going quickly. You don't actually have to pedal at all. It's totally motorized. Also, we went at 9p which was a great way to avoid the Vegas sun. Such a memorable way to spend time in Vegas and check out bars you didn't know about!\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words befor cleaning, and removing stopwords: 164\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words befor cleaning, and removing stopwords: {}\".format(len(corpus[3].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "st = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaner.clean_stem(corpus, tokenizer, lemma, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"had great time now i want vega pub crawler every time i come vega there three separate group ride two larger group husband we used groupon all need show driver phone printed he'll take photo super easy we bit timid first driver jon loosened u kept u happy we spent minute spot they decently close block apart there drinking actual vehicle but issue since stopping going quickly you actually pedal it's totally motorized also went 9p great way avoid vega sun such memorable way spend time vega check bar know\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 28562)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"stars_rev\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb = GaussianNB()\n",
    "# nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confu(y_test, y_pred):\n",
    "    tp, tn, fp, fn = 0,0,0,0\n",
    "    for x,y in zip(y_test, y_pred):\n",
    "        if x == y:\n",
    "            if x > 3:\n",
    "                tp+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "        elif x != y:\n",
    "            if y>3:\n",
    "                fp+=1\n",
    "            else:\n",
    "                fn+1\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, y_pred):\n",
    "    tp, tn, fp, fn = confu(y_test, y_pred)\n",
    "    matrix = np.array([[tp, fp], [fn, tn]])\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(fp+tp)\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    return matrix, recall, precision, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix, recall, precision, accuracy = metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating evaluation metrics\n",
    "# matrix, recall, precision, accuracy = cleaner.metrics(y_test=y_test, y_predict=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8699, 5799],\n",
       "       [   0, 3092]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 100.0%\n",
      "Precision: 60.0%\n",
      "Accuracy: 67.03%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1_5.select(\"review_star\").groupBy(\"review_star\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_terms, neg_terms = cleaner.show_topics(lreg.coef_, terms, length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('best', 6.80288704363611),\n",
       " ('amazing', 6.622382200229562),\n",
       " ('awesome', 4.535405439351903),\n",
       " ('delicious', 4.277399571478582),\n",
       " ('perfect', 4.065658104108061),\n",
       " ('thank', 3.994333611317463),\n",
       " ('love', 3.968631816344425),\n",
       " ('excellent', 3.9313464274445726),\n",
       " ('favorite', 3.926740625353595),\n",
       " ('highly', 3.9040771553051092),\n",
       " ('fantastic', 3.728577419700471),\n",
       " ('incredible', 3.6323654294201813),\n",
       " ('outstanding', 3.492029098096073),\n",
       " ('great', 3.360544985924977),\n",
       " ('wonderful', 3.3207934317339034),\n",
       " ('omg', 3.193340716373476),\n",
       " ('bomb', 3.1786127401807396),\n",
       " ('heaven', 3.0898723003510087),\n",
       " ('perfectly', 3.084994302889382),\n",
       " ('perfection', 3.0413323922309328),\n",
       " ('professional', 3.032409150813298),\n",
       " ('gem', 2.96818216419987),\n",
       " ('loved', 2.839264735031425),\n",
       " ('notch', 2.8185192761240714),\n",
       " ('phenomenal', 2.7314482232615167),\n",
       " ('deserves', 2.6504540536066648),\n",
       " ('die', 2.6448899743417615),\n",
       " ('holy', 2.5746937359281943),\n",
       " ('ryan', 2.565273268148959),\n",
       " ('wow', 2.5320142204333966),\n",
       " ('exceptional', 2.5303600835715465),\n",
       " ('blast', 2.4678428735278),\n",
       " ('ebc', 2.4518553332278854),\n",
       " ('fresh', 2.4350532145754653),\n",
       " ('absolutely', 2.4112938455116053),\n",
       " ('fabulous', 2.397979481215766),\n",
       " ('knowledgeable', 2.3744780094591253),\n",
       " ('vega', 2.347646654729454),\n",
       " ('team', 2.330393954212305),\n",
       " ('pinball', 2.322291136796276)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', -6.270885271731235),\n",
       " ('ok', -5.932618592623465),\n",
       " ('bland', -5.784663404694461),\n",
       " ('okay', -5.457155411756951),\n",
       " ('rude', -5.393969482220618),\n",
       " ('horrible', -5.3169206990282305),\n",
       " ('terrible', -5.161410966603913),\n",
       " ('mediocre', -4.944914024164714),\n",
       " ('average', -4.572687372075172),\n",
       " ('disappointing', -4.441483613712197),\n",
       " ('slow', -4.403267251308377),\n",
       " ('overpriced', -4.278535670122588),\n",
       " ('pretty', -4.187652856054678),\n",
       " ('meh', -3.768321124043735),\n",
       " ('decent', -3.6601788765431396),\n",
       " ('overall', -3.5415174070826936),\n",
       " ('dirty', -3.4601718107756985),\n",
       " ('poor', -3.4241857182983173),\n",
       " ('reason', -3.403739760443927),\n",
       " ('star', -3.3394465144306626),\n",
       " ('dry', -3.2499340101487575),\n",
       " ('awful', -3.2158835748545647),\n",
       " ('guess', -3.148097172897898),\n",
       " ('solid', -3.1275940302188325),\n",
       " ('lack', -3.123415473134199),\n",
       " ('unfortunately', -3.1074134110982423),\n",
       " ('alright', -3.0996945433182184),\n",
       " ('asked', -3.0867740580455947),\n",
       " ('cold', -3.064045415802472),\n",
       " ('disgusting', -3.0448264900847817),\n",
       " ('lacking', -2.971037259575052),\n",
       " ('worse', -2.9282272656262807),\n",
       " ('suck', -2.9135848967891502),\n",
       " ('bad', -2.788355637379978),\n",
       " ('lacked', -2.780467385311885),\n",
       " ('expensive', -2.719568675795577),\n",
       " ('charged', -2.6586720692068395),\n",
       " ('instead', -2.578504634149563),\n",
       " ('used', -2.55879338115464),\n",
       " ('maybe', -2.4606024024025084)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARK DATAFRAME PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                text|review_star|\n",
      "+--------------------+-----------+\n",
      "|Enjoyed a delicio...|          5|\n",
      "|Had a great time ...|          5|\n",
      "+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spk = df1.limit(7000)\n",
    "df_spk.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test, df_train = df_spk.randomSplit(weights=[0.3, 0.7], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for trainset: 4876\n",
      "Number of rows for testset: 2124\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows for trainset: {}\".format(df_train.count()))\n",
    "print(\"Number of rows for testset: {}\".format(df_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tokenized = regex_tokenizer.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized.select(\"text\", \"words\", \"review_star\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|                text|               words|review_star|tokens|            filtered|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|\"A once in a life...|[a, once, in, a, ...|          5|   180|[lifetime, experi...|\n",
      "|\"Forrest, what's ...|[forrest, what, s...|          5|   304|[forrest, going, ...|\n",
      "|\"Garbage baked in...|[garbage, baked, ...|          1|   210|[garbage, baked, ...|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_removed_df = remover.transform(tokenized_df)\n",
    "stops_removed_df.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            filtered|label|\n",
      "+--------------------+-----+\n",
      "|[lifetime, experi...|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df = stops_removed_df.selectExpr(\"filtered\", \"review_star as label\")\n",
    "input_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|filtered                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[enjoyed, delicious, meal, family, friday, night, enjoyed, tasty, appetizers, fantastic, menu, beer, delicious, pizzas, service, friendly, mediterranean, pizza, awesome, along, sausage, pepperoni, wait, return]                                                                                                                                                             |\n",
      "|[great, time, family, cool, place, fried, chicken, sandwich, bbq, chicken, flatbread, burger, sliders, everything, great, including, cheese, curd, appetizers, oh, drinks, great, margarita, fresh, squeezed, limes, totally, refreshing, hot, summer, day, definitely, coming, back]                                                                                          |\n",
      "|[came, several, times, friends, good, quality, authentic, italian, pizzas, reasonable, price, good, variety, pizzas, organic, recommend, friends]                                                                                                                                                                                                                              |\n",
      "|[disappointed, used, one, favorite, restaurants, town, fresh, food, reasonable, price, freedom, make, bowl, changed, system, ppl, make, bowl, female, server, made, bowl, oct, 26, rude, rushing, making, sure, didn, get, much, food, m, never, coming, back, also, spread, words, friends, come, ps, charged, extra, 2, getting, proteins, didn, know, paid, invisible, menu]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.select(\"filtered\").show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            filtered|label|         rawFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|[lifetime, experi...|    5|(262144,[8443,880...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o5957.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 956.0 failed 1 times, most recent failure: Lost task 0.0 in stage 956.0 (TID 24925, localhost, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1008)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1128)\n\tat org.apache.spark.mllib.feature.IDF.fit(IDF.scala:54)\n\tat org.apache.spark.ml.feature.IDF.fit(IDF.scala:92)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-641-365d4abe07f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rawFeatures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidfModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturizedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturizedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \"\"\"\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o5957.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 956.0 failed 1 times, most recent failure: Lost task 0.0 in stage 956.0 (TID 24925, localhost, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1008)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1128)\n\tat org.apache.spark.mllib.feature.IDF.fit(IDF.scala:54)\n\tat org.apache.spark.ml.feature.IDF.fit(IDF.scala:92)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "tfidfModel = idf.fit(featurizedData).transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|filtered                                                                                                                                                                                                                                                                             |label|rawFeatures                                                                                                                                                                                                                                                                                                                                       |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[enjoyed, delicious, meal, family, friday, night, enjoyed, tasty, appetizers, fantastic, menu, beer, delicious, pizzas, service, friendly, mediterranean, pizza, awesome, along, sausage, pepperoni, wait, return]                                                                   |5    |(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])                                                                                             |(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.2547645704446624,2.558968478389122,5.298517346550703,2.3332442804814204,5.083405966933757,3.0493330302837727,3.8352619442946843,2.590467145448493,3.590139486261699,4.0065336649020535,2.5184566094722207,3.257641423707081,2.421568608986679,2.3007870703340387,1.8684086213941276,2.742841625874495,3.5134468654734445,3.922273321284314,6.379034005258645,4.0747419149285875,2.827033717094843,1.8946568474690637])                                                                                                                                                                                                                              |\n",
      "|[great, time, family, cool, place, fried, chicken, sandwich, bbq, chicken, flatbread, burger, sliders, everything, great, including, cheese, curd, appetizers, oh, drinks, great, margarita, fresh, squeezed, limes, totally, refreshing, hot, summer, day, definitely, coming, back]|5    |(262144,[13957,14592,32274,33773,36243,42343,50285,61231,65702,72609,73366,79737,89663,92064,93850,104983,114357,121517,126934,129113,132270,138356,163877,167290,168011,177070,199014,216410,223619,228586,233585],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(262144,[13957,14592,32274,33773,36243,42343,50285,61231,65702,72609,73366,79737,89663,92064,93850,104983,114357,121517,126934,129113,132270,138356,163877,167290,168011,177070,199014,216410,223619,228586,233585],[2.6257489595931327,5.684179827362688,5.083405966933757,6.725633702190849,6.032486521630903,2.840639369150622,3.963516279818363,0.9599202698041575,2.046593667636302,3.0493330302837727,3.0039644252539213,2.3519753171874838,4.0747419149285875,6.437951629739068,2.123802417468272,5.744804449179123,3.318896140153078,1.5007834875246846,2.9264061909080468,4.240727052402848,1.4751069994791606,3.0373533090681977,4.466518020696204,2.712258202502415,2.5159782934577537,3.922273321284314,2.3148576542309813,4.8285137173049675,3.5757507488095994,3.984793678265648,2.907921376233944])|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfModel.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.2547645704446624,2.558968478389122,5.298517346550703,2.3332442804814204,5.083405966933757,3.0493330302837727,3.8352619442946843,2.590467145448493,3.590139486261699,4.0065336649020535,2.5184566094722207,3.257641423707081,2.421568608986679,2.3007870703340387,1.8684086213941276,2.742841625874495,3.5134468654734445,3.922273321284314,6.379034005258645,4.0747419149285875,2.827033717094843,1.8946568474690637])|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfModel.select(\"features\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "model = lr.fit(tfidfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                text|review_star|\n",
      "+--------------------+-----------+\n",
      "|I was visiting Ma...|          5|\n",
      "+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_test = df1.subtract(df_train).limit(1250)\n",
    "# df_test.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test TFIDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_test = regex_tokenizer.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_test.select(\"text\", \"words\", \"review_star\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|                text|               words|review_star|tokens|            filtered|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|\"A once in a life...|[a, once, in, a, ...|          5|   180|[lifetime, experi...|\n",
      "|\"Forrest, what's ...|[forrest, what, s...|          5|   304|[forrest, going, ...|\n",
      "|\"Garbage baked in...|[garbage, baked, ...|          1|   210|[garbage, baked, ...|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_removed_df = remover.transform(tokenized_df)\n",
    "stops_removed_df.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_df_test = stops_removed_df_test.selectExpr(\"filtered\", \"review_star as label\")\n",
    "featurizedData_test = hashingTF.transform(input_df_test)\n",
    "tfidfModel_test = idf.fit(featurizedData_test).transform(featurizedData_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(tfidfModel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "|filtered|label|rawFeatures|features|rawPrediction|probability|prediction|\n",
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.where(prediction.prediction != prediction.label).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            filtered|label|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|[enjoyed, delicio...|    5|(262144,[24113,27...|(262144,[24113,27...|[-2.5715539192712...|[8.65336402638732...|       5.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = prediction.select([\"prediction\", \"label\"]).createTempView(\"predictions2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = spark.sql(\"SELECT SUM(CASE WHEN prediction = 5 AND label = 5 THEN 1 ELSE 0 END) AS tp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 1 THEN 1 ELSE 0 END) AS tn, \\\n",
    "                              SUM(CASE WHEN prediction = 5 AND label = 1 THEN 1 ELSE 0 END) AS fp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 5 THEN 1 ELSE 0 END) AS fn \\\n",
    "                      FROM predictions2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+---+\n",
      "|  tp|  tn| fp| fn|\n",
      "+----+----+---+---+\n",
      "|3930|1070|  0|  0|\n",
      "+----+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, recall, precision, accuracy = cleaner.metrics(df=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3930,    0],\n",
       "       [   0, 1070]])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 100.0%\n",
      "Precision: 100.0%\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = model.coefficientMatrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90906"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2.0)\n",
    "model_cv = cv.fit(input_df)\n",
    "result = model_cv.transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8546"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cv.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model_cv = lr.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            filtered|label|\n",
      "+--------------------+-----+\n",
      "|[enjoyed, delicio...|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df_test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe without labels\n",
    "input_df_test_cv = input_df_test.select(\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cv = cv.fit(input_df_test)\n",
    "result_test = model_cv.transform(input_df_test)\n",
    "prediction = lr_model_cv.transform(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "|filtered|label|features|rawPrediction|probability|prediction|\n",
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.where(prediction.prediction != prediction.label).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8546"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cv.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = prediction.join(input_df_test, [\"filtered\"], \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = prediction.select([\"prediction\", \"label\"]).createTempView(\"predictions4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = spark.sql(\"SELECT SUM(CASE WHEN prediction = 5 AND label = 5 THEN 1 ELSE 0 END) AS tp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 1 THEN 1 ELSE 0 END) AS tn, \\\n",
    "                              SUM(CASE WHEN prediction = 5 AND label = 1 THEN 1 ELSE 0 END) AS fp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 5 THEN 1 ELSE 0 END) AS fn \\\n",
    "                      FROM predictions4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+---+\n",
      "|  tp|  tn| fp| fn|\n",
      "+----+----+---+---+\n",
      "|3930|1070|  0|  0|\n",
      "+----+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix, recall, precision, accuracy = cleaner.metrics(df=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3930,    0],\n",
       "       [   0, 1070]])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DenseMatrix.toSparse of DenseMatrix(6, 8546, [-0.0014, -0.0013, -0.0015, -0.0012, -0.002, -0.0009, -0.001, -0.0014, ..., 0.1127, -0.0709, -0.0482, 0.1296, 0.2178, -0.6063, -0.0029, 0.1646], 1)>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_cv.coefficientMatrix.toSparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(6, 8546, [-0.0014, -0.0013, -0.0015, -0.0012, -0.002, -0.0009, -0.001, -0.0014, ..., 0.1127, -0.0709, -0.0482, 0.1296, 0.2178, -0.6063, -0.0029, 0.1646], 1)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_cv.coefficientMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 100.0%\n",
      "Precision: 100.0%\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food',\n",
       " 'great',\n",
       " 'place',\n",
       " 'good',\n",
       " 'service',\n",
       " 'one',\n",
       " 'like',\n",
       " 'madison',\n",
       " 'time',\n",
       " 'back',\n",
       " 've',\n",
       " 'go',\n",
       " 'get',\n",
       " 'best',\n",
       " 'also',\n",
       " 'restaurant',\n",
       " 'really',\n",
       " 'delicious',\n",
       " 'ordered',\n",
       " 'menu',\n",
       " 'well',\n",
       " 'us',\n",
       " 'love',\n",
       " 'order',\n",
       " 'cheese',\n",
       " 'got',\n",
       " 'pizza',\n",
       " 'always',\n",
       " 'even',\n",
       " 'amazing',\n",
       " 'friendly',\n",
       " 'staff',\n",
       " 'nice',\n",
       " 'm',\n",
       " 'chicken',\n",
       " 'never',\n",
       " 'try',\n",
       " 'came',\n",
       " 'bar',\n",
       " 'ever',\n",
       " 'definitely',\n",
       " 'first',\n",
       " 'made',\n",
       " 'dinner',\n",
       " 'went',\n",
       " 'wait',\n",
       " 'sauce',\n",
       " 'eat',\n",
       " 'come',\n",
       " 'people',\n",
       " 'night',\n",
       " 'favorite',\n",
       " 'excellent',\n",
       " 'little',\n",
       " 'fresh',\n",
       " 'make',\n",
       " 'much',\n",
       " 're',\n",
       " 'lunch',\n",
       " 'table',\n",
       " 'beer',\n",
       " 'didn',\n",
       " 'everything',\n",
       " 'two',\n",
       " 'meal',\n",
       " 'know',\n",
       " 'experience',\n",
       " 'recommend',\n",
       " 'every',\n",
       " 'minutes',\n",
       " 'salad',\n",
       " 'going',\n",
       " 'way',\n",
       " 'atmosphere',\n",
       " '5',\n",
       " 'better',\n",
       " 'coffee',\n",
       " 'drinks',\n",
       " 'times',\n",
       " 'new',\n",
       " 'sandwich',\n",
       " 'burger',\n",
       " 'perfect',\n",
       " 'tried',\n",
       " 'right',\n",
       " 'want',\n",
       " 'side',\n",
       " '2',\n",
       " 'small',\n",
       " 'sure',\n",
       " 'pretty',\n",
       " 'many',\n",
       " 'take',\n",
       " 'awesome',\n",
       " 'say',\n",
       " 'day',\n",
       " 'breakfast',\n",
       " 'think',\n",
       " 'area',\n",
       " 'said',\n",
       " 'next',\n",
       " 'dish',\n",
       " 'last',\n",
       " 'll',\n",
       " 'hot',\n",
       " 'fries',\n",
       " 'something',\n",
       " 'quality',\n",
       " 'worth',\n",
       " 'still',\n",
       " 'd',\n",
       " 'server',\n",
       " '3',\n",
       " 'location',\n",
       " 'fried',\n",
       " 'around',\n",
       " 'top',\n",
       " 'fantastic',\n",
       " 'find',\n",
       " 'took',\n",
       " 'town',\n",
       " 'bread',\n",
       " 'give',\n",
       " 'enough',\n",
       " 'bad',\n",
       " 'drink',\n",
       " 'another',\n",
       " 'special',\n",
       " 'fish',\n",
       " 'flavor',\n",
       " 'lot',\n",
       " 'meat',\n",
       " 'price',\n",
       " 'long',\n",
       " 'sweet',\n",
       " 'thing',\n",
       " 'though',\n",
       " 'taste',\n",
       " 'pork',\n",
       " 'since',\n",
       " 'dishes',\n",
       " 'tasty',\n",
       " 'places',\n",
       " 'friends',\n",
       " '10',\n",
       " 'bit',\n",
       " 'waitress',\n",
       " 'home',\n",
       " 'super',\n",
       " 'visit',\n",
       " 'see',\n",
       " 'old',\n",
       " 'selection',\n",
       " 'served',\n",
       " 'big',\n",
       " 'rice',\n",
       " 'happy',\n",
       " 'told',\n",
       " 'different',\n",
       " 'prices',\n",
       " 'soup',\n",
       " 'looking',\n",
       " 'asked',\n",
       " 'family',\n",
       " 'spicy',\n",
       " 'husband',\n",
       " 'things',\n",
       " 'wonderful',\n",
       " 'options',\n",
       " 'away',\n",
       " 'cooked',\n",
       " 'feel',\n",
       " 'highly',\n",
       " 'loved',\n",
       " 'busy',\n",
       " '1',\n",
       " 'restaurants',\n",
       " 'full',\n",
       " 'years',\n",
       " 'eating',\n",
       " 'without',\n",
       " 'absolutely',\n",
       " 'tasted',\n",
       " '4',\n",
       " 'coming',\n",
       " 'steak',\n",
       " 'wine',\n",
       " 'half',\n",
       " 'wasn',\n",
       " 'large',\n",
       " 'left',\n",
       " 'dining',\n",
       " 'local',\n",
       " 'beef',\n",
       " 'friend',\n",
       " 'free',\n",
       " 'everyone',\n",
       " 'fast',\n",
       " 'disappointed',\n",
       " 'probably',\n",
       " 'spot',\n",
       " 'work',\n",
       " 'fun',\n",
       " 'wanted',\n",
       " 'cold',\n",
       " 'enjoyed',\n",
       " 'found',\n",
       " 'anything',\n",
       " 'bacon',\n",
       " 'quite',\n",
       " 'far',\n",
       " 'hour',\n",
       " 'put',\n",
       " 'wisconsin',\n",
       " 'wife',\n",
       " 'thought',\n",
       " 'dessert',\n",
       " 'cream',\n",
       " 'house',\n",
       " 'brunch',\n",
       " 'kind',\n",
       " 'tables',\n",
       " 'curds',\n",
       " 'let',\n",
       " 'plate',\n",
       " 'ask',\n",
       " 'mexican',\n",
       " 'stop',\n",
       " 'perfectly',\n",
       " 'else',\n",
       " 'check',\n",
       " 'burgers',\n",
       " 'stars',\n",
       " 'decided',\n",
       " 'group',\n",
       " 'nothing',\n",
       " 'huge',\n",
       " 'authentic',\n",
       " 'sushi',\n",
       " 'kitchen',\n",
       " 'seated',\n",
       " 'three',\n",
       " 'ingredients',\n",
       " 'manager',\n",
       " 'need',\n",
       " 'review',\n",
       " 'done',\n",
       " 'chinese',\n",
       " 'must',\n",
       " 'oh',\n",
       " 'reviews',\n",
       " 'high',\n",
       " 'week',\n",
       " 'egg',\n",
       " 'business',\n",
       " 'items',\n",
       " 'chef',\n",
       " 'eaten',\n",
       " 'wrong',\n",
       " 'actually',\n",
       " 'shrimp',\n",
       " 'won',\n",
       " 'outside',\n",
       " 'owner',\n",
       " 'almost',\n",
       " 'star',\n",
       " 'real',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'usually',\n",
       " 'especially',\n",
       " 'overall',\n",
       " 'waiting',\n",
       " 'red',\n",
       " 'street',\n",
       " 'vegetarian',\n",
       " 'getting',\n",
       " 'enjoy',\n",
       " 'open',\n",
       " 'clean',\n",
       " 'inside',\n",
       " 'tacos',\n",
       " 'room',\n",
       " 'curry',\n",
       " 'maybe',\n",
       " 'attentive',\n",
       " 'finally',\n",
       " 'several',\n",
       " 'couldn',\n",
       " 'beers',\n",
       " 'ate',\n",
       " 'potatoes',\n",
       " 'warm',\n",
       " '6',\n",
       " 'friday',\n",
       " 'flavors',\n",
       " 'portions',\n",
       " 'worst',\n",
       " 'quick',\n",
       " 'least',\n",
       " 'crust',\n",
       " '30',\n",
       " 'yet',\n",
       " 'waited',\n",
       " 'decor',\n",
       " 'eggs',\n",
       " 'couple',\n",
       " 'hard',\n",
       " 'chocolate',\n",
       " 'chips',\n",
       " 'used',\n",
       " 'point',\n",
       " '15',\n",
       " 'reasonable',\n",
       " 'called',\n",
       " 'makes',\n",
       " 'second',\n",
       " 'stopped',\n",
       " 'however',\n",
       " 'someone',\n",
       " 'trying',\n",
       " 'customer',\n",
       " 'flavorful',\n",
       " '20',\n",
       " 'thai',\n",
       " 'end',\n",
       " 'extremely',\n",
       " 'walked',\n",
       " 'wish',\n",
       " 'unique',\n",
       " 'appetizer',\n",
       " 'comes',\n",
       " 'delivery',\n",
       " 'cool',\n",
       " 'terrible',\n",
       " 'meals',\n",
       " 'whole',\n",
       " 'sit',\n",
       " 'space',\n",
       " 'waiter',\n",
       " 'bartender',\n",
       " 'arrived',\n",
       " 'list',\n",
       " 'felt',\n",
       " 'indian',\n",
       " 'sandwiches',\n",
       " 'variety',\n",
       " 'party',\n",
       " 'tell',\n",
       " 'bring',\n",
       " 'music',\n",
       " 'started',\n",
       " 'kids',\n",
       " 'part',\n",
       " 'brought',\n",
       " 'outstanding',\n",
       " 'seating',\n",
       " 'may',\n",
       " 'gave',\n",
       " 'water',\n",
       " 'doesn',\n",
       " 'course',\n",
       " 'plates',\n",
       " 'today',\n",
       " 'live',\n",
       " 'sat',\n",
       " 'return',\n",
       " 'year',\n",
       " 'ice',\n",
       " 'yes',\n",
       " 'store',\n",
       " 'keep',\n",
       " 'late',\n",
       " 'care',\n",
       " 'seemed',\n",
       " 'later',\n",
       " 'person',\n",
       " 'garlic',\n",
       " 'instead',\n",
       " 'helpful',\n",
       " 'lots',\n",
       " 'either',\n",
       " 'anyone',\n",
       " 'french',\n",
       " 'name',\n",
       " 'fry',\n",
       " 'beans',\n",
       " 'bite',\n",
       " 'bowl',\n",
       " 'extra',\n",
       " 'making',\n",
       " 'portion',\n",
       " 'amount',\n",
       " 'green',\n",
       " 'line',\n",
       " 'tea',\n",
       " 'potato',\n",
       " 'often',\n",
       " 'door',\n",
       " 'wow',\n",
       " 'customers',\n",
       " 'leave',\n",
       " 'less',\n",
       " 'sausage',\n",
       " 'use',\n",
       " '8',\n",
       " 'money',\n",
       " 'expect',\n",
       " 'fine',\n",
       " 'serve',\n",
       " 'sunday',\n",
       " 'decent',\n",
       " 'light',\n",
       " 'drive',\n",
       " 'might',\n",
       " 'crispy',\n",
       " 'pie',\n",
       " 'haven',\n",
       " 'although',\n",
       " 'style',\n",
       " 'bill',\n",
       " 'completely',\n",
       " 'boyfriend',\n",
       " 'mac',\n",
       " 'grilled',\n",
       " 'isn',\n",
       " 'bbq',\n",
       " 'soon',\n",
       " 'italian',\n",
       " 'priced',\n",
       " 'start',\n",
       " 'twice',\n",
       " 'pick',\n",
       " 'rolls',\n",
       " 'world',\n",
       " 'yummy',\n",
       " 'ordering',\n",
       " 'ok',\n",
       " 'incredible',\n",
       " 'walk',\n",
       " 'cake',\n",
       " 'saturday',\n",
       " 'call',\n",
       " 'evening',\n",
       " 'buffet',\n",
       " 'pasta',\n",
       " '7',\n",
       " 'close',\n",
       " 'glad',\n",
       " 'tomato',\n",
       " 'noodles',\n",
       " 'ago',\n",
       " 'counter',\n",
       " 'fan',\n",
       " 'wings',\n",
       " 'entire',\n",
       " 'liked',\n",
       " 'front',\n",
       " 'seriously',\n",
       " 'slow',\n",
       " 'yelp',\n",
       " 'plenty',\n",
       " 'ambiance',\n",
       " 'trip',\n",
       " 'salsa',\n",
       " 'short',\n",
       " 'glass',\n",
       " 'shop',\n",
       " 'beautiful',\n",
       " 'roll',\n",
       " 'entrees',\n",
       " 'cocktails',\n",
       " 'please',\n",
       " 'able',\n",
       " 'taco',\n",
       " 'regular',\n",
       " 'recommended',\n",
       " 'already',\n",
       " 'cheap',\n",
       " 'guy',\n",
       " 'fact',\n",
       " 'appetizers',\n",
       " 'hands',\n",
       " 'parking',\n",
       " 'date',\n",
       " 'stuff',\n",
       " 'saw',\n",
       " 'rude',\n",
       " 'pancakes',\n",
       " 'prepared',\n",
       " 'pizzas',\n",
       " 'bloody',\n",
       " '50',\n",
       " 'choices',\n",
       " 'sitting',\n",
       " 'offer',\n",
       " 'chicago',\n",
       " 'ready',\n",
       " 'literally',\n",
       " 'plus',\n",
       " 'baked',\n",
       " 'mind',\n",
       " 'yum',\n",
       " 'tap',\n",
       " 'near',\n",
       " 'life',\n",
       " 'tip',\n",
       " 'homemade',\n",
       " 'impressed',\n",
       " 'choice',\n",
       " 'pay',\n",
       " 'given',\n",
       " 'toast',\n",
       " 'butter',\n",
       " 'seafood',\n",
       " 'seems',\n",
       " 'quickly',\n",
       " 'salmon',\n",
       " 'state',\n",
       " 'mouth',\n",
       " 'along',\n",
       " 'weekend',\n",
       " 'wouldn',\n",
       " 'size',\n",
       " 'hours',\n",
       " 'past',\n",
       " 'early',\n",
       " 'reason',\n",
       " 'believe',\n",
       " 'morning',\n",
       " 'orders',\n",
       " 'fashioned',\n",
       " 'asian',\n",
       " 'specials',\n",
       " 'horrible',\n",
       " 'lived',\n",
       " 'medium',\n",
       " 'bland',\n",
       " 'seem',\n",
       " 'ended',\n",
       " 'five',\n",
       " 'gets',\n",
       " 'simple',\n",
       " 'dry',\n",
       " 'remember',\n",
       " 'lamb',\n",
       " 'including',\n",
       " 'awful',\n",
       " 'cozy',\n",
       " 'working',\n",
       " 'entree',\n",
       " 'together',\n",
       " 'others',\n",
       " 'etc',\n",
       " 'crab',\n",
       " 'job',\n",
       " 'birthday',\n",
       " 'heard',\n",
       " 'favorites',\n",
       " 'offered',\n",
       " 'generous',\n",
       " 'truly',\n",
       " 'white',\n",
       " 'burrito',\n",
       " 'downtown',\n",
       " 'tastes',\n",
       " 'neighborhood',\n",
       " 'main',\n",
       " 'view',\n",
       " 'veggies',\n",
       " 'pleasant',\n",
       " 'cut',\n",
       " 'knew',\n",
       " 'corn',\n",
       " 'vegan',\n",
       " 'opened',\n",
       " 'added',\n",
       " 'surprised',\n",
       " 'game',\n",
       " 'choose',\n",
       " 'cafe',\n",
       " 'totally',\n",
       " 'rare',\n",
       " 'greasy',\n",
       " 'sauces',\n",
       " 'phone',\n",
       " 'deal',\n",
       " 'salads',\n",
       " 'lovely',\n",
       " 'behind',\n",
       " 'thank',\n",
       " 'add',\n",
       " 'onion',\n",
       " 'forward',\n",
       " 'mary',\n",
       " 'cuisine',\n",
       " 'thin',\n",
       " 'rest',\n",
       " 'hungry',\n",
       " 'cup',\n",
       " 'problem',\n",
       " 'exactly',\n",
       " 'packed',\n",
       " 'veggie',\n",
       " 'owners',\n",
       " 'sometimes',\n",
       " 'onions',\n",
       " 'days',\n",
       " 'easy',\n",
       " 'employees',\n",
       " 'easily',\n",
       " 'salty',\n",
       " 'tonight',\n",
       " 'die',\n",
       " 'received',\n",
       " 'certainly',\n",
       " 'based',\n",
       " 'sides',\n",
       " 'run',\n",
       " 'visited',\n",
       " 'pho',\n",
       " 'loud',\n",
       " 'visiting',\n",
       " 'desserts',\n",
       " 'incredibly',\n",
       " 'mixed',\n",
       " 'pieces',\n",
       " 'paid',\n",
       " 'serving',\n",
       " 'needed',\n",
       " 'sour',\n",
       " 'recently',\n",
       " 'city',\n",
       " 'four',\n",
       " 'gem',\n",
       " 'option',\n",
       " 'toppings',\n",
       " 'anywhere',\n",
       " 'black',\n",
       " 'miss',\n",
       " 'hit',\n",
       " 'across',\n",
       " 'honestly',\n",
       " 'patio',\n",
       " 'single',\n",
       " 'simply',\n",
       " 'shared',\n",
       " 'empty',\n",
       " 'guys',\n",
       " 'rather',\n",
       " 'immediately',\n",
       " 'filling',\n",
       " 'addition',\n",
       " 'interesting',\n",
       " 'broth',\n",
       " 'thanks',\n",
       " 'tender',\n",
       " 'pulled',\n",
       " 'type',\n",
       " 'blue',\n",
       " 'vegetables',\n",
       " 'share',\n",
       " 'servers',\n",
       " 'dirty',\n",
       " 'number',\n",
       " 'expected',\n",
       " 'rich',\n",
       " 'taking',\n",
       " 'gluten',\n",
       " 'moved',\n",
       " 'gone',\n",
       " '12',\n",
       " 'saying',\n",
       " 'okay',\n",
       " 'n',\n",
       " 'excited',\n",
       " 'east',\n",
       " 'bun',\n",
       " 'due',\n",
       " 'pot',\n",
       " 'establishment',\n",
       " 'bakery',\n",
       " 'tofu',\n",
       " 'dumplings',\n",
       " 'cook',\n",
       " 'reservation',\n",
       " 'ramen',\n",
       " 'slice',\n",
       " 'help',\n",
       " 'bartenders',\n",
       " 'building',\n",
       " 'cost',\n",
       " 'delivered',\n",
       " 'poor',\n",
       " 'looks',\n",
       " 'set',\n",
       " '9',\n",
       " 'tuna',\n",
       " 'ribs',\n",
       " 'soft',\n",
       " 'greeted',\n",
       " 'finish',\n",
       " 'hope',\n",
       " 'summer',\n",
       " 'fabulous',\n",
       " 'tasting',\n",
       " 'lobster',\n",
       " 'average',\n",
       " 'cocktail',\n",
       " 'phenomenal',\n",
       " 'traditional',\n",
       " 'sorry',\n",
       " 'gravy',\n",
       " 'mix',\n",
       " 'vibe',\n",
       " 'dark',\n",
       " 'level',\n",
       " 'reservations',\n",
       " 'roasted',\n",
       " 'american',\n",
       " 'seen',\n",
       " 'lettuce',\n",
       " 'man',\n",
       " 'watch',\n",
       " 'kept',\n",
       " 'months',\n",
       " 'club',\n",
       " 'duck',\n",
       " 'clearly',\n",
       " 'daughter',\n",
       " 'non',\n",
       " 'unless',\n",
       " 'expensive',\n",
       " 'lemon',\n",
       " 'seat',\n",
       " 'finished',\n",
       " 'split',\n",
       " 'read',\n",
       " 'west',\n",
       " 'casual',\n",
       " 'chili',\n",
       " 'hostess',\n",
       " 'wall',\n",
       " 'slightly',\n",
       " '45',\n",
       " 'son',\n",
       " 'perfection',\n",
       " 'pub',\n",
       " 'talking',\n",
       " 'show',\n",
       " 'guess',\n",
       " 'buy',\n",
       " 'chance',\n",
       " 'cute',\n",
       " 'treat',\n",
       " 'stuffed',\n",
       " 'creamy',\n",
       " 'happened',\n",
       " 'grab',\n",
       " 'feeling',\n",
       " 'texture',\n",
       " 'mushrooms',\n",
       " 'weren',\n",
       " 'spring',\n",
       " 'knowledgeable',\n",
       " 'spinach',\n",
       " 'fair',\n",
       " 'true',\n",
       " 'crowded',\n",
       " 'change',\n",
       " 'solid',\n",
       " 'smoked',\n",
       " 'savory',\n",
       " 'noodle',\n",
       " 'case',\n",
       " 'available',\n",
       " 'cash',\n",
       " 'minute',\n",
       " 'spice',\n",
       " 'says',\n",
       " 'tomatoes',\n",
       " 'biscuits',\n",
       " 'management',\n",
       " 'conversation',\n",
       " 'diner',\n",
       " 'satisfied',\n",
       " 'hash',\n",
       " 'within',\n",
       " 'filled',\n",
       " 'st',\n",
       " 'affordable',\n",
       " 'longer',\n",
       " 'deep',\n",
       " 'stay',\n",
       " 'la',\n",
       " 'oil',\n",
       " 'noticed',\n",
       " 'avoid',\n",
       " 'crisp',\n",
       " 'hand',\n",
       " 'mine',\n",
       " 'thinking',\n",
       " 'despite',\n",
       " 'forget',\n",
       " 'unfortunately',\n",
       " 'whatever',\n",
       " 'head',\n",
       " 'typical',\n",
       " 'card',\n",
       " 'hotel',\n",
       " 'square',\n",
       " 'mention',\n",
       " 'talk',\n",
       " 'low',\n",
       " 'notch',\n",
       " 'locally',\n",
       " '40',\n",
       " 'avocado',\n",
       " 'idea',\n",
       " 'upon',\n",
       " 'tiny',\n",
       " 'topped',\n",
       " 'piece',\n",
       " 'lady',\n",
       " 'taken',\n",
       " 'gotten',\n",
       " 'outdoor',\n",
       " 'returning',\n",
       " 'meats',\n",
       " 'seasoned',\n",
       " 'beyond',\n",
       " 'capitol',\n",
       " 'pad',\n",
       " 'plan',\n",
       " 'disappointing',\n",
       " 'note',\n",
       " 'pricey',\n",
       " 'charge',\n",
       " 'multiple',\n",
       " 'ones',\n",
       " 'grill',\n",
       " 'juicy',\n",
       " 'lake',\n",
       " 'frozen',\n",
       " 'grocery',\n",
       " 'falafel',\n",
       " 'brisket',\n",
       " 'cooking',\n",
       " 'mushroom',\n",
       " 'obviously',\n",
       " 'fancy',\n",
       " 'needs',\n",
       " 'belly',\n",
       " 'comfortable',\n",
       " 'wi',\n",
       " 'event',\n",
       " 'spend',\n",
       " 'touch',\n",
       " 'greens',\n",
       " 'mediocre',\n",
       " 'folks',\n",
       " 'pepper',\n",
       " 'bars',\n",
       " 'sign',\n",
       " 'closed',\n",
       " 'rib',\n",
       " 'sort',\n",
       " 'understand',\n",
       " 'normally',\n",
       " 'fruit',\n",
       " 'polite',\n",
       " 'combination',\n",
       " 'guests',\n",
       " 'missing',\n",
       " 'strong',\n",
       " 'interior',\n",
       " 'mean',\n",
       " 'sick',\n",
       " 'whether',\n",
       " 'margaritas',\n",
       " 'consistently',\n",
       " 'fairly',\n",
       " 'weeks',\n",
       " 'takes',\n",
       " '11',\n",
       " 'bottle',\n",
       " 'mom',\n",
       " 'combo',\n",
       " 'paying',\n",
       " 'kid',\n",
       " 'afternoon',\n",
       " 'middle',\n",
       " 'reasonably',\n",
       " 'worked',\n",
       " 'fat',\n",
       " 'dine',\n",
       " 'bag',\n",
       " 'floor',\n",
       " 'boy',\n",
       " 'prompt',\n",
       " 'dip',\n",
       " 'mentioned',\n",
       " 'ahead',\n",
       " 'sun',\n",
       " 'play',\n",
       " 'chose',\n",
       " 'hidden',\n",
       " 'double',\n",
       " 'giving',\n",
       " 'standard',\n",
       " 'treated',\n",
       " 'creative',\n",
       " 'previous',\n",
       " 'become',\n",
       " 'nachos',\n",
       " 'nicely',\n",
       " 'limited',\n",
       " 'credit',\n",
       " 'mall',\n",
       " 'hear',\n",
       " 'dressing',\n",
       " 'goat',\n",
       " 'foods',\n",
       " 'monday',\n",
       " 'suggest',\n",
       " 'attention',\n",
       " 'environment',\n",
       " 'welcoming',\n",
       " 'thick',\n",
       " 'general',\n",
       " 'fare',\n",
       " 'original',\n",
       " 'classic',\n",
       " 'wrap',\n",
       " 'aren',\n",
       " 'cilantro',\n",
       " 'item',\n",
       " 'craving',\n",
       " 'impressive',\n",
       " 'crowd',\n",
       " 'crunchy',\n",
       " 'spent',\n",
       " 'nights',\n",
       " '100',\n",
       " 'college',\n",
       " '00',\n",
       " 'alone',\n",
       " 'heaven',\n",
       " 'pleased',\n",
       " 'cod',\n",
       " 'experiences',\n",
       " 'wedding',\n",
       " 'box',\n",
       " 'chain',\n",
       " 'complaint',\n",
       " 'matter',\n",
       " 'turned',\n",
       " 'dog',\n",
       " 'sized',\n",
       " 'window',\n",
       " 'opening',\n",
       " 'ravioli',\n",
       " 'mostly',\n",
       " 'recommendations',\n",
       " 'nearby',\n",
       " 'slices',\n",
       " 'squash',\n",
       " 'thru',\n",
       " 'bell',\n",
       " 'supposed',\n",
       " 'drinking',\n",
       " 'total',\n",
       " 'expecting',\n",
       " 'dane',\n",
       " 'walking',\n",
       " 'changed',\n",
       " 'craft',\n",
       " 'vegetable',\n",
       " 'e',\n",
       " 'coleslaw',\n",
       " 'mussels',\n",
       " 'located',\n",
       " 'ian',\n",
       " 'platter',\n",
       " 'young',\n",
       " 'playing',\n",
       " 'anyway',\n",
       " 'exceptional',\n",
       " 'none',\n",
       " 'o',\n",
       " 'healthy',\n",
       " 'soda',\n",
       " 'absolute',\n",
       " 'corner',\n",
       " 'save',\n",
       " 'selections',\n",
       " 'running',\n",
       " 'cheddar',\n",
       " 'disgusting',\n",
       " 'mistake',\n",
       " ...]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
