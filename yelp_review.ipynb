{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"df lecture\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "import cleaner\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = spark.read.json('../break_week/data/dataset/review.json')\n",
    "user_df = spark.read.json('../break_week/data/dataset/user.json')\n",
    "business_df = spark.read.json(\"../break_week/data/dataset/business.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_df.createTempView(\"review\")\n",
    "user_df.createTempView(\"user\")\n",
    "business_df.createTempView(\"business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"SELECT new.user_name, new.user_id, new.business_id, new.friends, \\\n",
    "                b.name AS business_name, b.state, b.city, b.address, b.categories, b.stars AS bus_star,\\\n",
    "                new.text, new.stars AS review_star \\\n",
    "                FROM \\\n",
    "                    (SELECT u.name AS user_name, r.user_id, r.business_id, r.text, r.stars, u.friends \\\n",
    "                    FROM review AS r \\\n",
    "                    LEFT JOIN user AS u \\\n",
    "                    ON r.user_id = u.user_id) AS new\\\n",
    "                INNER JOIN business as b\\\n",
    "                ON new.business_id = b.business_id \\\n",
    "                WHERE ARRAY_CONTAINS(b.categories, 'Restaurants') \\\n",
    "                AND b.state IN (\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\", \\\n",
    "                                \"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\", \\\n",
    "                                \"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\") \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+--------------------+-----+---------+--------------------+--------------------+--------+--------------------+-----------+\n",
      "|user_name|             user_id|         business_id|             friends|       business_name|state|     city|             address|          categories|bus_star|                text|review_star|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+-----+---------+--------------------+--------------------+--------+--------------------+-----------+\n",
      "|   Justin|0y8ORuC2X1i1UF6SG...|--9e1ONYQuAa-CB_R...|[sf-8AusztxHc4o5b...|Delmonico Steakhouse|   NV|Las Vegas|3355 Las Vegas Bl...|[Cajun/Creole, St...|     4.0|WOW.\n",
      "\n",
      "I came to V...|          5|\n",
      "|        J|A4GnBOU7ZCTcoQK4e...|--9e1ONYQuAa-CB_R...|[MGPQVLsODMm9ZtYQ...|Delmonico Steakhouse|   NV|Las Vegas|3355 Las Vegas Bl...|[Cajun/Creole, St...|     4.0|This restaurant i...|          5|\n",
      "+---------+--------------------+--------------------+--------------------+--------------------+-----+---------+--------------------+--------------------+--------+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1_5 = df.filter(\"review_star = 1 OR review_star = 5\")\n",
    "df_1_5.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1333392"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_5.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|state|count |\n",
      "+-----+------+\n",
      "|AZ   |492259|\n",
      "|SC   |3481  |\n",
      "|VA   |1     |\n",
      "|NV   |543049|\n",
      "|WI   |32850 |\n",
      "|CA   |2     |\n",
      "|NC   |95105 |\n",
      "|IL   |11183 |\n",
      "|IN   |12    |\n",
      "|OH   |82870 |\n",
      "|PA   |72525 |\n",
      "|NY   |35    |\n",
      "|CO   |4     |\n",
      "|AK   |16    |\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1_5.select(\"state\").groupBy(\"state\").count().show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df_1_5.where(\"state = 'WI'\").select([\"text\", \"review_star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "# wordsData = tokenizer.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wi = df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoyed a delicious meal with family on Friday...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Had a great time with family at this cool plac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Came several times with my friends. Very good ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very disappointed. It used to be one my favori...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My favorite place to have chicken wings! Ike t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Location is perfect is u r shopping or after a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Newly opened Chinese home style cuisine. Great...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Great Belgian restaurant. Had mussels and frie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One of the best and authentic Chinese restaura...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Love this place! Authentic and fresh dishes! T...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  review_star\n",
       "0  Enjoyed a delicious meal with family on Friday...            5\n",
       "1  Had a great time with family at this cool plac...            5\n",
       "2  Came several times with my friends. Very good ...            5\n",
       "3  Very disappointed. It used to be one my favori...            1\n",
       "4  My favorite place to have chicken wings! Ike t...            5\n",
       "5  Location is perfect is u r shopping or after a...            5\n",
       "6  Newly opened Chinese home style cuisine. Great...            5\n",
       "7  Great Belgian restaurant. Had mussels and frie...            5\n",
       "8  One of the best and authentic Chinese restaura...            5\n",
       "9  Love this place! Authentic and fresh dishes! T...            5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = df_wi[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Very disappointed. It used to be one my favorite restaurants in the town: fresh food, reasonable price and the freedom to make my own bowl! Now they changed their system so their ppl make your bowl. AND the female server who made my bowl, on oct 26, was very rude! She was rushing and making sure I didn't get too much of the food! I'm never coming back again. I will also spread the words to my friends not to come.\\n\\nPs: they charged for extra $2 for getting proteins, which I didn't know until I paid!! And this was very invisible on the menu!\""
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words(\"english\"))\n",
    "# sw.update([\"i\", \"and\", \"i'm\", \"she\", \"he\"])\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "st = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaner.clean_stem(corpus, tokenizer, lemma, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very',\n",
       " 'disappointed',\n",
       " 'it',\n",
       " 'used',\n",
       " 'one',\n",
       " 'favorite',\n",
       " 'restaurant',\n",
       " 'town',\n",
       " 'fresh',\n",
       " 'food',\n",
       " 'reasonable',\n",
       " 'price',\n",
       " 'freedom',\n",
       " 'make',\n",
       " 'bowl',\n",
       " 'now',\n",
       " 'changed',\n",
       " 'system',\n",
       " 'ppl',\n",
       " 'make',\n",
       " 'bowl',\n",
       " 'and',\n",
       " 'female',\n",
       " 'server',\n",
       " 'made',\n",
       " 'bowl',\n",
       " 'oct',\n",
       " 'rude',\n",
       " 'she',\n",
       " 'rushing',\n",
       " 'making',\n",
       " 'sure',\n",
       " 'i',\n",
       " 'get',\n",
       " 'much',\n",
       " 'food',\n",
       " \"i'm\",\n",
       " 'never',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'i',\n",
       " 'also',\n",
       " 'spread',\n",
       " 'word',\n",
       " 'friend',\n",
       " 'come',\n",
       " 'p',\n",
       " 'charged',\n",
       " 'extra',\n",
       " 'getting',\n",
       " 'protein',\n",
       " 'i',\n",
       " 'know',\n",
       " 'i',\n",
       " 'paid',\n",
       " 'and',\n",
       " 'invisible',\n",
       " 'menu']"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32850, 18102)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_wi[\"review_star\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb = GaussianNB()\n",
    "# nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating evaluation metrics\n",
    "matrix, recall, precision, accuracy = cleaner.metrics(y_test=y_test, y_predict=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6434,  219],\n",
       "       [  50, 1510]])"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 99.23%\n",
      "Precision: 96.71%\n",
      "Accuracy: 96.72%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ['great', 'delicious', 'amazing', 'best', 'excellent', 'love', 'awesome', 'favorite', 'friendly', 'perfect', 'fantastic', 'madison', 'definitely', 'loved', 'wonderful', 'good', 'happy', 'fresh', 'nice', 'perfectly', 'highly', 'tasty', 'outstanding', 've', 'enjoyed', 'fun', 'little', 'attentive', 'fast', 'super', 'yummy', 'incredible', 'thank', 'flavorful', 'bit', 'helpful', 'yum', 'try', 'notch', 'reasonable']\n"
     ]
    }
   ],
   "source": [
    "cleaner.show_topics(lreg.coef_, terms, length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ['worst', 'terrible', 'horrible', 'bland', 'awful', 'rude', 'disappointing', 'poor', 'mediocre', 'bad', 'minute', 'told', 'ok', 'dry', 'asked', 'disgusting', 'tasted', 'cold', 'overpriced', 'tasteless', 'money', 'slow', 'dirty', 'ordered', 'gross', 'worse', 'customer', 'charged', 'frozen', 'left', 'flavorless', 'management', 'said', 'disappointment', 'waste', 'unfortunately', 'soggy', 'waited', 'barely', 'sorry']\n"
     ]
    }
   ],
   "source": [
    "cleaner.show_topics(lreg.coef_, terms, length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|review_star|  count|\n",
      "+-----------+-------+\n",
      "|          5|1031519|\n",
      "|          1| 301873|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1_5.select(\"review_star\").groupBy(\"review_star\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_terms, neg_terms = cleaner.show_topics(lreg.coef_, terms, length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 9.6339199219398921),\n",
       " ('delicious', 9.5086695708994373),\n",
       " ('amazing', 7.9170599102536379),\n",
       " ('best', 7.3589483682208217),\n",
       " ('excellent', 6.6895446573983914),\n",
       " ('love', 6.3849393517080557),\n",
       " ('awesome', 5.6882532659470213),\n",
       " ('favorite', 5.6378331048222989),\n",
       " ('friendly', 5.3344655463092208),\n",
       " ('perfect', 5.1487301606386211),\n",
       " ('fantastic', 4.9271576211302959),\n",
       " ('madison', 4.5292909003664485),\n",
       " ('definitely', 4.486343438415247),\n",
       " ('loved', 4.0306943032514306),\n",
       " ('wonderful', 3.9535371632915139),\n",
       " ('good', 3.8106663126652971),\n",
       " ('happy', 3.7261373823249087),\n",
       " ('fresh', 3.4802625832525842),\n",
       " ('nice', 3.3065880195360347),\n",
       " ('perfectly', 3.0823391451468418),\n",
       " ('highly', 2.9778623076666277),\n",
       " ('tasty', 2.9082167789912066),\n",
       " ('outstanding', 2.8545282365526417),\n",
       " ('ve', 2.8206297853641185),\n",
       " ('enjoyed', 2.6887189898520636),\n",
       " ('fun', 2.596468899456712),\n",
       " ('little', 2.5549889693513079),\n",
       " ('attentive', 2.5345851110853932),\n",
       " ('fast', 2.4638339969770398),\n",
       " ('super', 2.3439106507574947),\n",
       " ('yummy', 2.3407288471590419),\n",
       " ('incredible', 2.333495306683453),\n",
       " ('thank', 2.3192592330362323),\n",
       " ('flavorful', 2.2727534003422805),\n",
       " ('bit', 2.257463602047121),\n",
       " ('helpful', 2.2478394635570775),\n",
       " ('yum', 2.1938197140672746),\n",
       " ('try', 2.1724875526296352),\n",
       " ('notch', 2.1302856301218953),\n",
       " ('reasonable', 2.107079463937191)]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', -7.8428487355547984),\n",
       " ('terrible', -6.3079030915106147),\n",
       " ('horrible', -5.751475018400706),\n",
       " ('bland', -5.1065524302327372),\n",
       " ('awful', -4.8790553173531208),\n",
       " ('rude', -4.6553109680826168),\n",
       " ('disappointing', -4.5527040275278674),\n",
       " ('poor', -4.5292789281254802),\n",
       " ('mediocre', -4.5238552456152945),\n",
       " ('bad', -4.4682088611261186),\n",
       " ('minute', -4.313426659289445),\n",
       " ('told', -3.9543664624267665),\n",
       " ('ok', -3.858301806403829),\n",
       " ('dry', -3.8292530674849785),\n",
       " ('asked', -3.5862004447195974),\n",
       " ('disgusting', -3.5675109238113314),\n",
       " ('tasted', -3.536419801643381),\n",
       " ('cold', -3.448647333203243),\n",
       " ('overpriced', -3.3473641044353819),\n",
       " ('tasteless', -3.3292811357064571),\n",
       " ('money', -3.2726399181447468),\n",
       " ('slow', -3.2396165759347912),\n",
       " ('dirty', -3.2147656019520117),\n",
       " ('ordered', -3.2110760494267212),\n",
       " ('gross', -3.1794458033762432),\n",
       " ('worse', -3.1079818464443512),\n",
       " ('customer', -2.9925095943697189),\n",
       " ('charged', -2.9689180757806759),\n",
       " ('frozen', -2.8625362889855053),\n",
       " ('left', -2.862506312445793),\n",
       " ('flavorless', -2.8176413482381366),\n",
       " ('management', -2.7533401007716223),\n",
       " ('said', -2.7399812916314623),\n",
       " ('disappointment', -2.6968281052132874),\n",
       " ('waste', -2.6751619119112071),\n",
       " ('unfortunately', -2.6709828452872486),\n",
       " ('soggy', -2.6622381580119558),\n",
       " ('waited', -2.6586246654747745),\n",
       " ('barely', -2.6073677537503377),\n",
       " ('sorry', -2.5424010638207819)]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARK DATAFRAME PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                text|review_star|\n",
      "+--------------------+-----------+\n",
      "|Enjoyed a delicio...|          5|\n",
      "|Had a great time ...|          5|\n",
      "+--------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spk = df1.limit(7000)\n",
    "df_spk.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test, df_train = df_spk.randomSplit(weights=[0.3, 0.7], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for trainset: 4876\n",
      "Number of rows for testset: 2124\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows for trainset: {}\".format(df_train.count()))\n",
    "print(\"Number of rows for testset: {}\".format(df_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tokenized = regex_tokenizer.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized.select(\"text\", \"words\", \"review_star\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|                text|               words|review_star|tokens|            filtered|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|\"A once in a life...|[a, once, in, a, ...|          5|   180|[lifetime, experi...|\n",
      "|\"Forrest, what's ...|[forrest, what, s...|          5|   304|[forrest, going, ...|\n",
      "|\"Garbage baked in...|[garbage, baked, ...|          1|   210|[garbage, baked, ...|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_removed_df = remover.transform(tokenized_df)\n",
    "stops_removed_df.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            filtered|label|\n",
      "+--------------------+-----+\n",
      "|[lifetime, experi...|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df = stops_removed_df.selectExpr(\"filtered\", \"review_star as label\")\n",
    "input_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|filtered                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[enjoyed, delicious, meal, family, friday, night, enjoyed, tasty, appetizers, fantastic, menu, beer, delicious, pizzas, service, friendly, mediterranean, pizza, awesome, along, sausage, pepperoni, wait, return]                                                                                                                                                             |\n",
      "|[great, time, family, cool, place, fried, chicken, sandwich, bbq, chicken, flatbread, burger, sliders, everything, great, including, cheese, curd, appetizers, oh, drinks, great, margarita, fresh, squeezed, limes, totally, refreshing, hot, summer, day, definitely, coming, back]                                                                                          |\n",
      "|[came, several, times, friends, good, quality, authentic, italian, pizzas, reasonable, price, good, variety, pizzas, organic, recommend, friends]                                                                                                                                                                                                                              |\n",
      "|[disappointed, used, one, favorite, restaurants, town, fresh, food, reasonable, price, freedom, make, bowl, changed, system, ppl, make, bowl, female, server, made, bowl, oct, 26, rude, rushing, making, sure, didn, get, much, food, m, never, coming, back, also, spread, words, friends, come, ps, charged, extra, 2, getting, proteins, didn, know, paid, invisible, menu]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.select(\"filtered\").show(4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            filtered|label|         rawFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|[lifetime, experi...|    5|(262144,[8443,880...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o5957.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 956.0 failed 1 times, most recent failure: Lost task 0.0 in stage 956.0 (TID 24925, localhost, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1008)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1128)\n\tat org.apache.spark.mllib.feature.IDF.fit(IDF.scala:54)\n\tat org.apache.spark.ml.feature.IDF.fit(IDF.scala:92)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-641-365d4abe07f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rawFeatures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidfModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturizedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturizedData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \"\"\"\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1160\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.1/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    319\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o5957.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 956.0 failed 1 times, most recent failure: Lost task 0.0 in stage 956.0 (TID 24925, localhost, executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1008)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1128)\n\tat org.apache.spark.mllib.feature.IDF.fit(IDF.scala:54)\n\tat org.apache.spark.ml.feature.IDF.fit(IDF.scala:92)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "tfidfModel = idf.fit(featurizedData).transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|filtered                                                                                                                                                                                                                                                                             |label|rawFeatures                                                                                                                                                                                                                                                                                                                                       |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[enjoyed, delicious, meal, family, friday, night, enjoyed, tasty, appetizers, fantastic, menu, beer, delicious, pizzas, service, friendly, mediterranean, pizza, awesome, along, sausage, pepperoni, wait, return]                                                                   |5    |(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0])                                                                                             |(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.2547645704446624,2.558968478389122,5.298517346550703,2.3332442804814204,5.083405966933757,3.0493330302837727,3.8352619442946843,2.590467145448493,3.590139486261699,4.0065336649020535,2.5184566094722207,3.257641423707081,2.421568608986679,2.3007870703340387,1.8684086213941276,2.742841625874495,3.5134468654734445,3.922273321284314,6.379034005258645,4.0747419149285875,2.827033717094843,1.8946568474690637])                                                                                                                                                                                                                              |\n",
      "|[great, time, family, cool, place, fried, chicken, sandwich, bbq, chicken, flatbread, burger, sliders, everything, great, including, cheese, curd, appetizers, oh, drinks, great, margarita, fresh, squeezed, limes, totally, refreshing, hot, summer, day, definitely, coming, back]|5    |(262144,[13957,14592,32274,33773,36243,42343,50285,61231,65702,72609,73366,79737,89663,92064,93850,104983,114357,121517,126934,129113,132270,138356,163877,167290,168011,177070,199014,216410,223619,228586,233585],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(262144,[13957,14592,32274,33773,36243,42343,50285,61231,65702,72609,73366,79737,89663,92064,93850,104983,114357,121517,126934,129113,132270,138356,163877,167290,168011,177070,199014,216410,223619,228586,233585],[2.6257489595931327,5.684179827362688,5.083405966933757,6.725633702190849,6.032486521630903,2.840639369150622,3.963516279818363,0.9599202698041575,2.046593667636302,3.0493330302837727,3.0039644252539213,2.3519753171874838,4.0747419149285875,6.437951629739068,2.123802417468272,5.744804449179123,3.318896140153078,1.5007834875246846,2.9264061909080468,4.240727052402848,1.4751069994791606,3.0373533090681977,4.466518020696204,2.712258202502415,2.5159782934577537,3.922273321284314,2.3148576542309813,4.8285137173049675,3.5757507488095994,3.984793678265648,2.907921376233944])|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfModel.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(262144,[24113,27823,46609,66092,70507,72609,79525,82495,96822,125011,127009,146009,146563,150069,151571,163436,174608,177070,179628,211177,227406,228685],[1.2547645704446624,2.558968478389122,5.298517346550703,2.3332442804814204,5.083405966933757,3.0493330302837727,3.8352619442946843,2.590467145448493,3.590139486261699,4.0065336649020535,2.5184566094722207,3.257641423707081,2.421568608986679,2.3007870703340387,1.8684086213941276,2.742841625874495,3.5134468654734445,3.922273321284314,6.379034005258645,4.0747419149285875,2.827033717094843,1.8946568474690637])|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfModel.select(\"features\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "model = lr.fit(tfidfModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                text|review_star|\n",
      "+--------------------+-----------+\n",
      "|I was visiting Ma...|          5|\n",
      "+--------------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_test = df1.subtract(df_train).limit(1250)\n",
    "# df_test.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building test TFIDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_test = regex_tokenizer.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countTokens = udf(lambda words: len(words), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_test.select(\"text\", \"words\", \"review_star\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|                text|               words|review_star|tokens|            filtered|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "|\"A once in a life...|[a, once, in, a, ...|          5|   180|[lifetime, experi...|\n",
      "|\"Forrest, what's ...|[forrest, what, s...|          5|   304|[forrest, going, ...|\n",
      "|\"Garbage baked in...|[garbage, baked, ...|          1|   210|[garbage, baked, ...|\n",
      "+--------------------+--------------------+-----------+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_removed_df = remover.transform(tokenized_df)\n",
    "stops_removed_df.show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_df_test = stops_removed_df_test.selectExpr(\"filtered\", \"review_star as label\")\n",
    "featurizedData_test = hashingTF.transform(input_df_test)\n",
    "tfidfModel_test = idf.fit(featurizedData_test).transform(featurizedData_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(tfidfModel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "|filtered|label|rawFeatures|features|rawPrediction|probability|prediction|\n",
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "+--------+-----+-----------+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.where(prediction.prediction != prediction.label).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|            filtered|label|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|[enjoyed, delicio...|    5|(262144,[24113,27...|(262144,[24113,27...|[-2.5715539192712...|[8.65336402638732...|       5.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = prediction.select([\"prediction\", \"label\"]).createTempView(\"predictions2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = spark.sql(\"SELECT SUM(CASE WHEN prediction = 5 AND label = 5 THEN 1 ELSE 0 END) AS tp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 1 THEN 1 ELSE 0 END) AS tn, \\\n",
    "                              SUM(CASE WHEN prediction = 5 AND label = 1 THEN 1 ELSE 0 END) AS fp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 5 THEN 1 ELSE 0 END) AS fn \\\n",
    "                      FROM predictions2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+---+\n",
      "|  tp|  tn| fp| fn|\n",
      "+----+----+---+---+\n",
      "|3930|1070|  0|  0|\n",
      "+----+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, recall, precision, accuracy = cleaner.metrics(df=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3930,    0],\n",
       "       [   0, 1070]])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 100.0%\n",
      "Precision: 100.0%\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta = model.coefficientMatrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90906"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", minDF=2.0)\n",
    "model_cv = cv.fit(input_df)\n",
    "result = model_cv.transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8546"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cv.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model_cv = lr.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            filtered|label|\n",
      "+--------------------+-----+\n",
      "|[enjoyed, delicio...|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df_test.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataframe without labels\n",
    "input_df_test_cv = input_df_test.select(\"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cv = cv.fit(input_df_test)\n",
    "result_test = model_cv.transform(input_df_test)\n",
    "prediction = lr_model_cv.transform(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "|filtered|label|features|rawPrediction|probability|prediction|\n",
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "+--------+-----+--------+-------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.where(prediction.prediction != prediction.label).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8546"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cv.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = prediction.join(input_df_test, [\"filtered\"], \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = prediction.select([\"prediction\", \"label\"]).createTempView(\"predictions4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = spark.sql(\"SELECT SUM(CASE WHEN prediction = 5 AND label = 5 THEN 1 ELSE 0 END) AS tp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 1 THEN 1 ELSE 0 END) AS tn, \\\n",
    "                              SUM(CASE WHEN prediction = 5 AND label = 1 THEN 1 ELSE 0 END) AS fp, \\\n",
    "                              SUM(CASE WHEN prediction = 1 AND label = 5 THEN 1 ELSE 0 END) AS fn \\\n",
    "                      FROM predictions4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+---+\n",
      "|  tp|  tn| fp| fn|\n",
      "+----+----+---+---+\n",
      "|3930|1070|  0|  0|\n",
      "+----+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix, recall, precision, accuracy = cleaner.metrics(df=metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3930,    0],\n",
       "       [   0, 1070]])"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DenseMatrix.toSparse of DenseMatrix(6, 8546, [-0.0014, -0.0013, -0.0015, -0.0012, -0.002, -0.0009, -0.001, -0.0014, ..., 0.1127, -0.0709, -0.0482, 0.1296, 0.2178, -0.6063, -0.0029, 0.1646], 1)>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_cv.coefficientMatrix.toSparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(6, 8546, [-0.0014, -0.0013, -0.0015, -0.0012, -0.002, -0.0009, -0.001, -0.0014, ..., 0.1127, -0.0709, -0.0482, 0.1296, 0.2178, -0.6063, -0.0029, 0.1646], 1)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_cv.coefficientMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 100.0%\n",
      "Precision: 100.0%\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}%\".format(round(recall*100, 2)))\n",
    "print(\"Precision: {}%\".format(round(precision*100, 2)))\n",
    "print(\"Accuracy: {}%\".format(round(accuracy*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['food',\n",
       " 'great',\n",
       " 'place',\n",
       " 'good',\n",
       " 'service',\n",
       " 'one',\n",
       " 'like',\n",
       " 'madison',\n",
       " 'time',\n",
       " 'back',\n",
       " 've',\n",
       " 'go',\n",
       " 'get',\n",
       " 'best',\n",
       " 'also',\n",
       " 'restaurant',\n",
       " 'really',\n",
       " 'delicious',\n",
       " 'ordered',\n",
       " 'menu',\n",
       " 'well',\n",
       " 'us',\n",
       " 'love',\n",
       " 'order',\n",
       " 'cheese',\n",
       " 'got',\n",
       " 'pizza',\n",
       " 'always',\n",
       " 'even',\n",
       " 'amazing',\n",
       " 'friendly',\n",
       " 'staff',\n",
       " 'nice',\n",
       " 'm',\n",
       " 'chicken',\n",
       " 'never',\n",
       " 'try',\n",
       " 'came',\n",
       " 'bar',\n",
       " 'ever',\n",
       " 'definitely',\n",
       " 'first',\n",
       " 'made',\n",
       " 'dinner',\n",
       " 'went',\n",
       " 'wait',\n",
       " 'sauce',\n",
       " 'eat',\n",
       " 'come',\n",
       " 'people',\n",
       " 'night',\n",
       " 'favorite',\n",
       " 'excellent',\n",
       " 'little',\n",
       " 'fresh',\n",
       " 'make',\n",
       " 'much',\n",
       " 're',\n",
       " 'lunch',\n",
       " 'table',\n",
       " 'beer',\n",
       " 'didn',\n",
       " 'everything',\n",
       " 'two',\n",
       " 'meal',\n",
       " 'know',\n",
       " 'experience',\n",
       " 'recommend',\n",
       " 'every',\n",
       " 'minutes',\n",
       " 'salad',\n",
       " 'going',\n",
       " 'way',\n",
       " 'atmosphere',\n",
       " '5',\n",
       " 'better',\n",
       " 'coffee',\n",
       " 'drinks',\n",
       " 'times',\n",
       " 'new',\n",
       " 'sandwich',\n",
       " 'burger',\n",
       " 'perfect',\n",
       " 'tried',\n",
       " 'right',\n",
       " 'want',\n",
       " 'side',\n",
       " '2',\n",
       " 'small',\n",
       " 'sure',\n",
       " 'pretty',\n",
       " 'many',\n",
       " 'take',\n",
       " 'awesome',\n",
       " 'say',\n",
       " 'day',\n",
       " 'breakfast',\n",
       " 'think',\n",
       " 'area',\n",
       " 'said',\n",
       " 'next',\n",
       " 'dish',\n",
       " 'last',\n",
       " 'll',\n",
       " 'hot',\n",
       " 'fries',\n",
       " 'something',\n",
       " 'quality',\n",
       " 'worth',\n",
       " 'still',\n",
       " 'd',\n",
       " 'server',\n",
       " '3',\n",
       " 'location',\n",
       " 'fried',\n",
       " 'around',\n",
       " 'top',\n",
       " 'fantastic',\n",
       " 'find',\n",
       " 'took',\n",
       " 'town',\n",
       " 'bread',\n",
       " 'give',\n",
       " 'enough',\n",
       " 'bad',\n",
       " 'drink',\n",
       " 'another',\n",
       " 'special',\n",
       " 'fish',\n",
       " 'flavor',\n",
       " 'lot',\n",
       " 'meat',\n",
       " 'price',\n",
       " 'long',\n",
       " 'sweet',\n",
       " 'thing',\n",
       " 'though',\n",
       " 'taste',\n",
       " 'pork',\n",
       " 'since',\n",
       " 'dishes',\n",
       " 'tasty',\n",
       " 'places',\n",
       " 'friends',\n",
       " '10',\n",
       " 'bit',\n",
       " 'waitress',\n",
       " 'home',\n",
       " 'super',\n",
       " 'visit',\n",
       " 'see',\n",
       " 'old',\n",
       " 'selection',\n",
       " 'served',\n",
       " 'big',\n",
       " 'rice',\n",
       " 'happy',\n",
       " 'told',\n",
       " 'different',\n",
       " 'prices',\n",
       " 'soup',\n",
       " 'looking',\n",
       " 'asked',\n",
       " 'family',\n",
       " 'spicy',\n",
       " 'husband',\n",
       " 'things',\n",
       " 'wonderful',\n",
       " 'options',\n",
       " 'away',\n",
       " 'cooked',\n",
       " 'feel',\n",
       " 'highly',\n",
       " 'loved',\n",
       " 'busy',\n",
       " '1',\n",
       " 'restaurants',\n",
       " 'full',\n",
       " 'years',\n",
       " 'eating',\n",
       " 'without',\n",
       " 'absolutely',\n",
       " 'tasted',\n",
       " '4',\n",
       " 'coming',\n",
       " 'steak',\n",
       " 'wine',\n",
       " 'half',\n",
       " 'wasn',\n",
       " 'large',\n",
       " 'left',\n",
       " 'dining',\n",
       " 'local',\n",
       " 'beef',\n",
       " 'friend',\n",
       " 'free',\n",
       " 'everyone',\n",
       " 'fast',\n",
       " 'disappointed',\n",
       " 'probably',\n",
       " 'spot',\n",
       " 'work',\n",
       " 'fun',\n",
       " 'wanted',\n",
       " 'cold',\n",
       " 'enjoyed',\n",
       " 'found',\n",
       " 'anything',\n",
       " 'bacon',\n",
       " 'quite',\n",
       " 'far',\n",
       " 'hour',\n",
       " 'put',\n",
       " 'wisconsin',\n",
       " 'wife',\n",
       " 'thought',\n",
       " 'dessert',\n",
       " 'cream',\n",
       " 'house',\n",
       " 'brunch',\n",
       " 'kind',\n",
       " 'tables',\n",
       " 'curds',\n",
       " 'let',\n",
       " 'plate',\n",
       " 'ask',\n",
       " 'mexican',\n",
       " 'stop',\n",
       " 'perfectly',\n",
       " 'else',\n",
       " 'check',\n",
       " 'burgers',\n",
       " 'stars',\n",
       " 'decided',\n",
       " 'group',\n",
       " 'nothing',\n",
       " 'huge',\n",
       " 'authentic',\n",
       " 'sushi',\n",
       " 'kitchen',\n",
       " 'seated',\n",
       " 'three',\n",
       " 'ingredients',\n",
       " 'manager',\n",
       " 'need',\n",
       " 'review',\n",
       " 'done',\n",
       " 'chinese',\n",
       " 'must',\n",
       " 'oh',\n",
       " 'reviews',\n",
       " 'high',\n",
       " 'week',\n",
       " 'egg',\n",
       " 'business',\n",
       " 'items',\n",
       " 'chef',\n",
       " 'eaten',\n",
       " 'wrong',\n",
       " 'actually',\n",
       " 'shrimp',\n",
       " 'won',\n",
       " 'outside',\n",
       " 'owner',\n",
       " 'almost',\n",
       " 'star',\n",
       " 'real',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'usually',\n",
       " 'especially',\n",
       " 'overall',\n",
       " 'waiting',\n",
       " 'red',\n",
       " 'street',\n",
       " 'vegetarian',\n",
       " 'getting',\n",
       " 'enjoy',\n",
       " 'open',\n",
       " 'clean',\n",
       " 'inside',\n",
       " 'tacos',\n",
       " 'room',\n",
       " 'curry',\n",
       " 'maybe',\n",
       " 'attentive',\n",
       " 'finally',\n",
       " 'several',\n",
       " 'couldn',\n",
       " 'beers',\n",
       " 'ate',\n",
       " 'potatoes',\n",
       " 'warm',\n",
       " '6',\n",
       " 'friday',\n",
       " 'flavors',\n",
       " 'portions',\n",
       " 'worst',\n",
       " 'quick',\n",
       " 'least',\n",
       " 'crust',\n",
       " '30',\n",
       " 'yet',\n",
       " 'waited',\n",
       " 'decor',\n",
       " 'eggs',\n",
       " 'couple',\n",
       " 'hard',\n",
       " 'chocolate',\n",
       " 'chips',\n",
       " 'used',\n",
       " 'point',\n",
       " '15',\n",
       " 'reasonable',\n",
       " 'called',\n",
       " 'makes',\n",
       " 'second',\n",
       " 'stopped',\n",
       " 'however',\n",
       " 'someone',\n",
       " 'trying',\n",
       " 'customer',\n",
       " 'flavorful',\n",
       " '20',\n",
       " 'thai',\n",
       " 'end',\n",
       " 'extremely',\n",
       " 'walked',\n",
       " 'wish',\n",
       " 'unique',\n",
       " 'appetizer',\n",
       " 'comes',\n",
       " 'delivery',\n",
       " 'cool',\n",
       " 'terrible',\n",
       " 'meals',\n",
       " 'whole',\n",
       " 'sit',\n",
       " 'space',\n",
       " 'waiter',\n",
       " 'bartender',\n",
       " 'arrived',\n",
       " 'list',\n",
       " 'felt',\n",
       " 'indian',\n",
       " 'sandwiches',\n",
       " 'variety',\n",
       " 'party',\n",
       " 'tell',\n",
       " 'bring',\n",
       " 'music',\n",
       " 'started',\n",
       " 'kids',\n",
       " 'part',\n",
       " 'brought',\n",
       " 'outstanding',\n",
       " 'seating',\n",
       " 'may',\n",
       " 'gave',\n",
       " 'water',\n",
       " 'doesn',\n",
       " 'course',\n",
       " 'plates',\n",
       " 'today',\n",
       " 'live',\n",
       " 'sat',\n",
       " 'return',\n",
       " 'year',\n",
       " 'ice',\n",
       " 'yes',\n",
       " 'store',\n",
       " 'keep',\n",
       " 'late',\n",
       " 'care',\n",
       " 'seemed',\n",
       " 'later',\n",
       " 'person',\n",
       " 'garlic',\n",
       " 'instead',\n",
       " 'helpful',\n",
       " 'lots',\n",
       " 'either',\n",
       " 'anyone',\n",
       " 'french',\n",
       " 'name',\n",
       " 'fry',\n",
       " 'beans',\n",
       " 'bite',\n",
       " 'bowl',\n",
       " 'extra',\n",
       " 'making',\n",
       " 'portion',\n",
       " 'amount',\n",
       " 'green',\n",
       " 'line',\n",
       " 'tea',\n",
       " 'potato',\n",
       " 'often',\n",
       " 'door',\n",
       " 'wow',\n",
       " 'customers',\n",
       " 'leave',\n",
       " 'less',\n",
       " 'sausage',\n",
       " 'use',\n",
       " '8',\n",
       " 'money',\n",
       " 'expect',\n",
       " 'fine',\n",
       " 'serve',\n",
       " 'sunday',\n",
       " 'decent',\n",
       " 'light',\n",
       " 'drive',\n",
       " 'might',\n",
       " 'crispy',\n",
       " 'pie',\n",
       " 'haven',\n",
       " 'although',\n",
       " 'style',\n",
       " 'bill',\n",
       " 'completely',\n",
       " 'boyfriend',\n",
       " 'mac',\n",
       " 'grilled',\n",
       " 'isn',\n",
       " 'bbq',\n",
       " 'soon',\n",
       " 'italian',\n",
       " 'priced',\n",
       " 'start',\n",
       " 'twice',\n",
       " 'pick',\n",
       " 'rolls',\n",
       " 'world',\n",
       " 'yummy',\n",
       " 'ordering',\n",
       " 'ok',\n",
       " 'incredible',\n",
       " 'walk',\n",
       " 'cake',\n",
       " 'saturday',\n",
       " 'call',\n",
       " 'evening',\n",
       " 'buffet',\n",
       " 'pasta',\n",
       " '7',\n",
       " 'close',\n",
       " 'glad',\n",
       " 'tomato',\n",
       " 'noodles',\n",
       " 'ago',\n",
       " 'counter',\n",
       " 'fan',\n",
       " 'wings',\n",
       " 'entire',\n",
       " 'liked',\n",
       " 'front',\n",
       " 'seriously',\n",
       " 'slow',\n",
       " 'yelp',\n",
       " 'plenty',\n",
       " 'ambiance',\n",
       " 'trip',\n",
       " 'salsa',\n",
       " 'short',\n",
       " 'glass',\n",
       " 'shop',\n",
       " 'beautiful',\n",
       " 'roll',\n",
       " 'entrees',\n",
       " 'cocktails',\n",
       " 'please',\n",
       " 'able',\n",
       " 'taco',\n",
       " 'regular',\n",
       " 'recommended',\n",
       " 'already',\n",
       " 'cheap',\n",
       " 'guy',\n",
       " 'fact',\n",
       " 'appetizers',\n",
       " 'hands',\n",
       " 'parking',\n",
       " 'date',\n",
       " 'stuff',\n",
       " 'saw',\n",
       " 'rude',\n",
       " 'pancakes',\n",
       " 'prepared',\n",
       " 'pizzas',\n",
       " 'bloody',\n",
       " '50',\n",
       " 'choices',\n",
       " 'sitting',\n",
       " 'offer',\n",
       " 'chicago',\n",
       " 'ready',\n",
       " 'literally',\n",
       " 'plus',\n",
       " 'baked',\n",
       " 'mind',\n",
       " 'yum',\n",
       " 'tap',\n",
       " 'near',\n",
       " 'life',\n",
       " 'tip',\n",
       " 'homemade',\n",
       " 'impressed',\n",
       " 'choice',\n",
       " 'pay',\n",
       " 'given',\n",
       " 'toast',\n",
       " 'butter',\n",
       " 'seafood',\n",
       " 'seems',\n",
       " 'quickly',\n",
       " 'salmon',\n",
       " 'state',\n",
       " 'mouth',\n",
       " 'along',\n",
       " 'weekend',\n",
       " 'wouldn',\n",
       " 'size',\n",
       " 'hours',\n",
       " 'past',\n",
       " 'early',\n",
       " 'reason',\n",
       " 'believe',\n",
       " 'morning',\n",
       " 'orders',\n",
       " 'fashioned',\n",
       " 'asian',\n",
       " 'specials',\n",
       " 'horrible',\n",
       " 'lived',\n",
       " 'medium',\n",
       " 'bland',\n",
       " 'seem',\n",
       " 'ended',\n",
       " 'five',\n",
       " 'gets',\n",
       " 'simple',\n",
       " 'dry',\n",
       " 'remember',\n",
       " 'lamb',\n",
       " 'including',\n",
       " 'awful',\n",
       " 'cozy',\n",
       " 'working',\n",
       " 'entree',\n",
       " 'together',\n",
       " 'others',\n",
       " 'etc',\n",
       " 'crab',\n",
       " 'job',\n",
       " 'birthday',\n",
       " 'heard',\n",
       " 'favorites',\n",
       " 'offered',\n",
       " 'generous',\n",
       " 'truly',\n",
       " 'white',\n",
       " 'burrito',\n",
       " 'downtown',\n",
       " 'tastes',\n",
       " 'neighborhood',\n",
       " 'main',\n",
       " 'view',\n",
       " 'veggies',\n",
       " 'pleasant',\n",
       " 'cut',\n",
       " 'knew',\n",
       " 'corn',\n",
       " 'vegan',\n",
       " 'opened',\n",
       " 'added',\n",
       " 'surprised',\n",
       " 'game',\n",
       " 'choose',\n",
       " 'cafe',\n",
       " 'totally',\n",
       " 'rare',\n",
       " 'greasy',\n",
       " 'sauces',\n",
       " 'phone',\n",
       " 'deal',\n",
       " 'salads',\n",
       " 'lovely',\n",
       " 'behind',\n",
       " 'thank',\n",
       " 'add',\n",
       " 'onion',\n",
       " 'forward',\n",
       " 'mary',\n",
       " 'cuisine',\n",
       " 'thin',\n",
       " 'rest',\n",
       " 'hungry',\n",
       " 'cup',\n",
       " 'problem',\n",
       " 'exactly',\n",
       " 'packed',\n",
       " 'veggie',\n",
       " 'owners',\n",
       " 'sometimes',\n",
       " 'onions',\n",
       " 'days',\n",
       " 'easy',\n",
       " 'employees',\n",
       " 'easily',\n",
       " 'salty',\n",
       " 'tonight',\n",
       " 'die',\n",
       " 'received',\n",
       " 'certainly',\n",
       " 'based',\n",
       " 'sides',\n",
       " 'run',\n",
       " 'visited',\n",
       " 'pho',\n",
       " 'loud',\n",
       " 'visiting',\n",
       " 'desserts',\n",
       " 'incredibly',\n",
       " 'mixed',\n",
       " 'pieces',\n",
       " 'paid',\n",
       " 'serving',\n",
       " 'needed',\n",
       " 'sour',\n",
       " 'recently',\n",
       " 'city',\n",
       " 'four',\n",
       " 'gem',\n",
       " 'option',\n",
       " 'toppings',\n",
       " 'anywhere',\n",
       " 'black',\n",
       " 'miss',\n",
       " 'hit',\n",
       " 'across',\n",
       " 'honestly',\n",
       " 'patio',\n",
       " 'single',\n",
       " 'simply',\n",
       " 'shared',\n",
       " 'empty',\n",
       " 'guys',\n",
       " 'rather',\n",
       " 'immediately',\n",
       " 'filling',\n",
       " 'addition',\n",
       " 'interesting',\n",
       " 'broth',\n",
       " 'thanks',\n",
       " 'tender',\n",
       " 'pulled',\n",
       " 'type',\n",
       " 'blue',\n",
       " 'vegetables',\n",
       " 'share',\n",
       " 'servers',\n",
       " 'dirty',\n",
       " 'number',\n",
       " 'expected',\n",
       " 'rich',\n",
       " 'taking',\n",
       " 'gluten',\n",
       " 'moved',\n",
       " 'gone',\n",
       " '12',\n",
       " 'saying',\n",
       " 'okay',\n",
       " 'n',\n",
       " 'excited',\n",
       " 'east',\n",
       " 'bun',\n",
       " 'due',\n",
       " 'pot',\n",
       " 'establishment',\n",
       " 'bakery',\n",
       " 'tofu',\n",
       " 'dumplings',\n",
       " 'cook',\n",
       " 'reservation',\n",
       " 'ramen',\n",
       " 'slice',\n",
       " 'help',\n",
       " 'bartenders',\n",
       " 'building',\n",
       " 'cost',\n",
       " 'delivered',\n",
       " 'poor',\n",
       " 'looks',\n",
       " 'set',\n",
       " '9',\n",
       " 'tuna',\n",
       " 'ribs',\n",
       " 'soft',\n",
       " 'greeted',\n",
       " 'finish',\n",
       " 'hope',\n",
       " 'summer',\n",
       " 'fabulous',\n",
       " 'tasting',\n",
       " 'lobster',\n",
       " 'average',\n",
       " 'cocktail',\n",
       " 'phenomenal',\n",
       " 'traditional',\n",
       " 'sorry',\n",
       " 'gravy',\n",
       " 'mix',\n",
       " 'vibe',\n",
       " 'dark',\n",
       " 'level',\n",
       " 'reservations',\n",
       " 'roasted',\n",
       " 'american',\n",
       " 'seen',\n",
       " 'lettuce',\n",
       " 'man',\n",
       " 'watch',\n",
       " 'kept',\n",
       " 'months',\n",
       " 'club',\n",
       " 'duck',\n",
       " 'clearly',\n",
       " 'daughter',\n",
       " 'non',\n",
       " 'unless',\n",
       " 'expensive',\n",
       " 'lemon',\n",
       " 'seat',\n",
       " 'finished',\n",
       " 'split',\n",
       " 'read',\n",
       " 'west',\n",
       " 'casual',\n",
       " 'chili',\n",
       " 'hostess',\n",
       " 'wall',\n",
       " 'slightly',\n",
       " '45',\n",
       " 'son',\n",
       " 'perfection',\n",
       " 'pub',\n",
       " 'talking',\n",
       " 'show',\n",
       " 'guess',\n",
       " 'buy',\n",
       " 'chance',\n",
       " 'cute',\n",
       " 'treat',\n",
       " 'stuffed',\n",
       " 'creamy',\n",
       " 'happened',\n",
       " 'grab',\n",
       " 'feeling',\n",
       " 'texture',\n",
       " 'mushrooms',\n",
       " 'weren',\n",
       " 'spring',\n",
       " 'knowledgeable',\n",
       " 'spinach',\n",
       " 'fair',\n",
       " 'true',\n",
       " 'crowded',\n",
       " 'change',\n",
       " 'solid',\n",
       " 'smoked',\n",
       " 'savory',\n",
       " 'noodle',\n",
       " 'case',\n",
       " 'available',\n",
       " 'cash',\n",
       " 'minute',\n",
       " 'spice',\n",
       " 'says',\n",
       " 'tomatoes',\n",
       " 'biscuits',\n",
       " 'management',\n",
       " 'conversation',\n",
       " 'diner',\n",
       " 'satisfied',\n",
       " 'hash',\n",
       " 'within',\n",
       " 'filled',\n",
       " 'st',\n",
       " 'affordable',\n",
       " 'longer',\n",
       " 'deep',\n",
       " 'stay',\n",
       " 'la',\n",
       " 'oil',\n",
       " 'noticed',\n",
       " 'avoid',\n",
       " 'crisp',\n",
       " 'hand',\n",
       " 'mine',\n",
       " 'thinking',\n",
       " 'despite',\n",
       " 'forget',\n",
       " 'unfortunately',\n",
       " 'whatever',\n",
       " 'head',\n",
       " 'typical',\n",
       " 'card',\n",
       " 'hotel',\n",
       " 'square',\n",
       " 'mention',\n",
       " 'talk',\n",
       " 'low',\n",
       " 'notch',\n",
       " 'locally',\n",
       " '40',\n",
       " 'avocado',\n",
       " 'idea',\n",
       " 'upon',\n",
       " 'tiny',\n",
       " 'topped',\n",
       " 'piece',\n",
       " 'lady',\n",
       " 'taken',\n",
       " 'gotten',\n",
       " 'outdoor',\n",
       " 'returning',\n",
       " 'meats',\n",
       " 'seasoned',\n",
       " 'beyond',\n",
       " 'capitol',\n",
       " 'pad',\n",
       " 'plan',\n",
       " 'disappointing',\n",
       " 'note',\n",
       " 'pricey',\n",
       " 'charge',\n",
       " 'multiple',\n",
       " 'ones',\n",
       " 'grill',\n",
       " 'juicy',\n",
       " 'lake',\n",
       " 'frozen',\n",
       " 'grocery',\n",
       " 'falafel',\n",
       " 'brisket',\n",
       " 'cooking',\n",
       " 'mushroom',\n",
       " 'obviously',\n",
       " 'fancy',\n",
       " 'needs',\n",
       " 'belly',\n",
       " 'comfortable',\n",
       " 'wi',\n",
       " 'event',\n",
       " 'spend',\n",
       " 'touch',\n",
       " 'greens',\n",
       " 'mediocre',\n",
       " 'folks',\n",
       " 'pepper',\n",
       " 'bars',\n",
       " 'sign',\n",
       " 'closed',\n",
       " 'rib',\n",
       " 'sort',\n",
       " 'understand',\n",
       " 'normally',\n",
       " 'fruit',\n",
       " 'polite',\n",
       " 'combination',\n",
       " 'guests',\n",
       " 'missing',\n",
       " 'strong',\n",
       " 'interior',\n",
       " 'mean',\n",
       " 'sick',\n",
       " 'whether',\n",
       " 'margaritas',\n",
       " 'consistently',\n",
       " 'fairly',\n",
       " 'weeks',\n",
       " 'takes',\n",
       " '11',\n",
       " 'bottle',\n",
       " 'mom',\n",
       " 'combo',\n",
       " 'paying',\n",
       " 'kid',\n",
       " 'afternoon',\n",
       " 'middle',\n",
       " 'reasonably',\n",
       " 'worked',\n",
       " 'fat',\n",
       " 'dine',\n",
       " 'bag',\n",
       " 'floor',\n",
       " 'boy',\n",
       " 'prompt',\n",
       " 'dip',\n",
       " 'mentioned',\n",
       " 'ahead',\n",
       " 'sun',\n",
       " 'play',\n",
       " 'chose',\n",
       " 'hidden',\n",
       " 'double',\n",
       " 'giving',\n",
       " 'standard',\n",
       " 'treated',\n",
       " 'creative',\n",
       " 'previous',\n",
       " 'become',\n",
       " 'nachos',\n",
       " 'nicely',\n",
       " 'limited',\n",
       " 'credit',\n",
       " 'mall',\n",
       " 'hear',\n",
       " 'dressing',\n",
       " 'goat',\n",
       " 'foods',\n",
       " 'monday',\n",
       " 'suggest',\n",
       " 'attention',\n",
       " 'environment',\n",
       " 'welcoming',\n",
       " 'thick',\n",
       " 'general',\n",
       " 'fare',\n",
       " 'original',\n",
       " 'classic',\n",
       " 'wrap',\n",
       " 'aren',\n",
       " 'cilantro',\n",
       " 'item',\n",
       " 'craving',\n",
       " 'impressive',\n",
       " 'crowd',\n",
       " 'crunchy',\n",
       " 'spent',\n",
       " 'nights',\n",
       " '100',\n",
       " 'college',\n",
       " '00',\n",
       " 'alone',\n",
       " 'heaven',\n",
       " 'pleased',\n",
       " 'cod',\n",
       " 'experiences',\n",
       " 'wedding',\n",
       " 'box',\n",
       " 'chain',\n",
       " 'complaint',\n",
       " 'matter',\n",
       " 'turned',\n",
       " 'dog',\n",
       " 'sized',\n",
       " 'window',\n",
       " 'opening',\n",
       " 'ravioli',\n",
       " 'mostly',\n",
       " 'recommendations',\n",
       " 'nearby',\n",
       " 'slices',\n",
       " 'squash',\n",
       " 'thru',\n",
       " 'bell',\n",
       " 'supposed',\n",
       " 'drinking',\n",
       " 'total',\n",
       " 'expecting',\n",
       " 'dane',\n",
       " 'walking',\n",
       " 'changed',\n",
       " 'craft',\n",
       " 'vegetable',\n",
       " 'e',\n",
       " 'coleslaw',\n",
       " 'mussels',\n",
       " 'located',\n",
       " 'ian',\n",
       " 'platter',\n",
       " 'young',\n",
       " 'playing',\n",
       " 'anyway',\n",
       " 'exceptional',\n",
       " 'none',\n",
       " 'o',\n",
       " 'healthy',\n",
       " 'soda',\n",
       " 'absolute',\n",
       " 'corner',\n",
       " 'save',\n",
       " 'selections',\n",
       " 'running',\n",
       " 'cheddar',\n",
       " 'disgusting',\n",
       " 'mistake',\n",
       " ...]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
